

```learning_adaptation/app.py
# app.py
from flask import Flask, request, jsonify, Response
import pandas as pd
import numpy as np
# from collections import OrderedDict
import json
import logging
import traceback
import requests
import torch
import shutil
from celery import Celery
import os
from flask_cors import CORS

from cgnn.config import set_config, get_config, set_initial_config
from tasks import train_and_evaluate_task

app = Flask(__name__)
CORS(app, resources={r"/*": {"origins": "*"}})
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)
app.config.update(
    CELERY_BROKER_URL='redis://redis:6379/2',
    CELERY_RESULT_BACKEND='redis://redis:6379/2'
)

celery = Celery(app.import_name, backend=app.config['CELERY_RESULT_BACKEND'], broker=app.config['CELERY_BROKER_URL'])
celery.conf.update(app.config)


@app.route('/cgnn_train_model', methods=['POST'])
def cgnn_train_models():
    try:
        train_files = request.files
        train_info_json = request.form.get('train_info')
        train_info = json.loads(train_info_json)

        train_array = pd.read_csv(train_files['train_array'], header=None).to_numpy(dtype=np.float32).tolist()
        test_array = pd.read_csv(train_files['test_array'], header=None).to_numpy(dtype=np.float32).tolist()
        anomaly_label_array = pd.read_csv(train_files['anomaly_label_array'], header=None).to_numpy(dtype=np.float32).tolist()

        logger.info("Received training request.")
        logger.debug(f"Train Info: {train_info}")

        task = train_and_evaluate_task.apply_async(args=[train_array, test_array, anomaly_label_array, train_info])

        return jsonify({"task_id": task.id}), 202
    except Exception as e:
        logger.error(traceback.format_exc())
        return jsonify({"error": str(e)}), 500


@app.route('/get_status/<task_id>', methods=['GET'])
def get_status(task_id):
    task = train_and_evaluate_task.AsyncResult(task_id)
    if task.state == 'PENDING':
        response = {
            'state': task.state,
            'status': 'Pending... (this may take a while)'
        }
    elif task.state != 'FAILURE':
        response = {
            'state': task.state,
            'status': task.info
        }
    else:
        response = {
            'state': task.state,
            'status': str(task.info)
        }
    return jsonify(response)


@app.route('/get_available_models', methods=['GET'])
def get_available_models():
    model_dir = 'trained_models_temp'
    models = {}
    for model_name in os.listdir(model_dir):
        model_path = os.path.join(model_dir, model_name)
        with open(os.path.join(model_path, 'model_params.json'), 'r') as f:
            params = json.load(f)
        with open(os.path.join(model_path, 'model_config.json'), 'r') as f:
            config = json.load(f)
        with open(os.path.join(model_path, 'model_evaluation.json'), 'r') as f:
            evaluation = json.load(f)
        models[model_name] = {'model_params': params, 'model_config': config, 'model_evaluation': evaluation}

    return jsonify(models)


@app.route('/save_to_detection_module', methods=['POST'])
def save_to_detection_module():
    model_info_json = request.form.get('model_info')
    model_info = json.loads(model_info_json)
    path = f"trained_models_temp/{next(iter(model_info['data']))}"
    model = torch.load(path+'/model.pt', map_location='cpu')
    json_data = {key: value.tolist() for key, value in model.items()}
    model_json = json.dumps(json_data, indent=2)

    try:
        model_info_json = json.dumps(model_info)
        response = requests.post(model_info['settings']['API_CGNN_ANOMALY_DETECTION_URL'] + '/save_model',
                                 files={'model': model_json}, data={'model_info': model_info_json})

        if response.status_code == 200:
            shutil.rmtree(path)
        return jsonify("success"), 200
    except Exception as e:
        logger.error(traceback.format_exc())
        return jsonify({"error": str(e)}), 500


@app.route('/cgnn_train_with_existing_dataset', methods=['POST'])
def cgnn_train_with_existing_dataset():
    train_info_json = request.form.get('train_info')
    train_info = json.loads(train_info_json)

    dataset = train_info['data']['dataset']
    directory = 'datasets/'+dataset
    test_label_filename = f"test_label_{dataset}"
    test_filename = f"test_{dataset}"
    train_filename = f"train_{dataset}"

    for filename in os.listdir(directory):
        if filename == test_label_filename:
            anomaly_label_array = pd.read_csv(directory+'/'+test_label_filename, header=None)
        elif filename == test_filename:
            test_array = pd.read_csv(directory+'/'+test_filename, header=None)
        elif filename == train_filename:
            train_array = pd.read_csv(directory+'/'+train_filename, header=None)

    # read the details.json from the directory
    details_file = os.path.join(directory, 'details.json')
    with open(details_file, 'r') as file:
        model_config = json.load(file)

    dataset_containers = model_config['containers']
    dataset_metrics = model_config['metrics']

    # Generate new headers for all combinations of containers and metrics
    new_headers = [f"{container}_{metric}" for container in dataset_containers for metric in dataset_metrics]
    # Rename the dataframe columns
    train_array.columns = new_headers
    test_array.columns = new_headers

    selected_containers = train_info['data']['containers']
    selected_metrics = train_info['data']['metrics']

    selected_headers = [f"{container}_{metric}" for container in selected_containers for metric in selected_metrics]
    train_array_filtered = train_array[selected_headers]
    test_array_filtered = test_array[selected_headers]

    train_files = {
        'train_array': train_array_filtered.to_csv(header=False, index=False),
        'test_array': test_array_filtered.to_csv(header=False, index=False),
        'anomaly_label_array': anomaly_label_array.to_csv(header=False, index=False)
    }
    train_info['data']['step_size'] = model_config['step_size']
    train_info['data']['duration'] = model_config['duration']
    train_info['data']['anomaly_sequence'] = model_config['anomaly_sequence']
    train_info['data']['data_entries'] = len(anomaly_label_array)

    train_info_json = json.dumps(train_info)
    print(train_info)
    try:
        response = requests.post(f'{train_info['settings']['API_DATA_PROCESSING_URL']}/preprocess_cgnn_train_data',
                                 files=train_files, data={'train_info': train_info_json})
        flask_response = Response(
            response.content,
            status=response.status_code,
            content_type=response.headers['Content-Type']
        )
        return flask_response
    except Exception as e:
        logger.error(traceback.format_exc())
        return jsonify({"error": str(e)}), 500


@app.route('/update_config', methods=['POST'])
def update_config():
    """
    Updates the configuration for the monitoring application.
    """
    new_config = request.json
    try:
        set_config(new_config)
        return jsonify({"success"}), 200
    except Exception as e:
        return jsonify({"error": str(e)}), 500


@app.route('/get_config', methods=['GET'])
def get_config_route():
    config = get_config()
    return jsonify(config)


@app.route('/get_available_datasets', methods=['GET'])
def get_available_datasets():
    combined_details = {}

    # Iterate over each directory in the datasets path
    for dir_name in os.listdir('datasets'):
        dir_path = os.path.join('datasets', dir_name)
        if os.path.isdir(dir_path):
            details_file = os.path.join(dir_path, 'details.json')
            if os.path.isfile(details_file):
                with open(details_file, 'r') as file:
                    details = json.load(file)
                    combined_details[dir_name] = details

    return combined_details


if __name__ == '__main__':
    set_initial_config()
    app.run(debug=True, host='0.0.0.0', port=5005)
```
```learning_adaptation/tasks.py
import numpy as np
import json
import logging
import os
import traceback
from celery import Celery

from cgnn.train import train
from cgnn.evaluate_prediction import predict_and_evaluate

logger = logging.getLogger(__name__)

celery = Celery('tasks', backend='redis://redis:6379/2', broker='redis://redis:6379/2')

# celery -A tasks worker --loglevel=info


@celery.task(bind=True)
def train_and_evaluate_task(self, train_array, test_array, anomaly_label_array, train_info):
    try:
        logger.info("Starting the training process.")
        model, model_config = train(train_info['data'], np.array(train_array, dtype=np.float32),
                                    np.array(test_array, dtype=np.float32), np.array(anomaly_label_array, dtype=np.float32))
        logger.info("Training completed.")

        logger.info("Starting the evaluation process.")
        predict_and_evaluate(model_config, model, np.array(train_array, dtype=np.float32),
                             np.array(test_array, dtype=np.float32), np.array(anomaly_label_array, dtype=np.float32))
        logger.info("Evaluation completed.")

        os.makedirs(f"trained_models_temp/{model_config['dataset']}_{model_config['id']}", exist_ok=True)
        with open(f"trained_models_temp/{model_config['dataset']}_{model_config['id']}/model_params.json", "w") as f:
            json.dump(train_info['data'], f, indent=2)
        return "Training Successful"
    except Exception as e:
        logger.error(traceback.format_exc())
        raise self.retry(exc=e, countdown=60)

```
```learning_adaptation/cgnn/config.py
# config.py
import os
import json

config_file_path = "config.json"


def set_initial_config():
    config = {
        # -- Data params ---
        # "dataset": os.getenv("DATASET", ""),
        # "group": os.getenv("GROUP", ""),
        "lookback": os.getenv("LOOKBACK", 100),
        # "normalize": os.getenv("NORMALIZE", True),
        "spec_res": os.getenv("SPEC_RES", False),
        # -- Model params ---
        # 1D conv layer
        "kernel_size": os.getenv("KERNEL_SIZE", 7),
        # GAT layers
        "use_gatv2": os.getenv("USE_GATV2", True),
        "feat_gat_embed_dim": os.getenv("FEAT_GAT_EMBED_DIM", None),
        "time_gat_embed_dim": os.getenv("TIME_GAT_EMBED_DIM", None),
        # GRU layer
        "gru_n_layers": os.getenv("GRU_N_LAYERS", 1),
        "gru_hid_dim": os.getenv("GRU_HID_DIM", 150),
        # Forecasting Model
        "fc_n_layers": os.getenv("FC_N_LAYERS", 3),
        "fc_hid_dim": os.getenv("FC_HID_DIM", 150),
        # Other
        "alpha": os.getenv("ALPHA", 0.2),
        # --- Train params ---
        "epochs": os.getenv("EPOCHS", 10),
        "val_split": os.getenv("VAL_SPLIT", 0.1),
        "bs": os.getenv("BS", 256),
        "init_lr": os.getenv("INIT_LR", 1e-3),
        "shuffle_dataset": os.getenv("SHUFFLE_DATASET", True),
        "dropout": os.getenv("DROPOUT", 0.4),
        "use_cuda": os.getenv("USE_CUDA", True),
        "print_every": os.getenv("PRINT_EVERY", 1),
        "log_tensorboard": os.getenv("LOG_TENSORBOARD", True),
        # --- Predictor params ---
        "scale_scores": os.getenv("SCALE_SCORES", False),
        "use_mov_av": os.getenv("USE_MOV_AV", False),
        "gamma": os.getenv("GAMMA", 1),
        "level": os.getenv("LEVEL", None),
        "q": os.getenv("Q", None),
        "reg_level": os.getenv("REG_LEVEL", 1),

        "dynamic_pot": os.getenv("DYNAMIC_POT", False),

        # --- Other ---
        "comment": os.getenv("COMMENT", "")
    }
    with open(config_file_path, 'w') as file:
        json.dump(config, file)


def get_config():
    with open(config_file_path, 'r') as file:
        config = json.load(file)
    return config


def set_config(new_config=None):
    # Update the configuration file with new settings
    config = get_config()
    if new_config:
        config.update(new_config)
    with open(config_file_path, 'w') as file:
        json.dump(config, file)


```
```learning_adaptation/cgnn/eval_methods.py
import numpy as np
import more_itertools as mit
from sklearn.metrics import ndcg_score

from cgnn.spot import SPOT


def adjust_predicts(score, label, threshold, pred=None, calc_latency=False):
    """
    Calculate adjusted predict labels using given `score`, `threshold` (or given `pred`) and `label`.
    Args:
            score (np.ndarray): The anomaly score
            label (np.ndarray): The ground-truth label
            threshold (float): The threshold of anomaly score.
                    A point is labeled as "anomaly" if its score is lower than the threshold.
            pred (np.ndarray or None): if not None, adjust `pred` and ignore `score` and `threshold`,
            calc_latency (bool):
    Returns:
            np.ndarray: predict labels

    Method from OmniAnomaly (https://github.com/NetManAIOps/OmniAnomaly)
    """
    if label is None:
        predict = score > threshold
        return predict, None

    if pred is None:
        if len(score) != len(label):
            raise ValueError("score and label must have the same length")
        predict = score > threshold
    else:
        predict = pred

    actual = label > 0.1
    anomaly_state = False
    anomaly_count = 0
    latency = 0

    for i in range(len(predict)):
        if any(actual[max(i, 0): i + 1]) and predict[i] and not anomaly_state:
            anomaly_state = True
            anomaly_count += 1
            for j in range(i, 0, -1):
                if not actual[j]:
                    break
                else:
                    if not predict[j]:
                        predict[j] = True
                        latency += 1
        elif not actual[i]:
            anomaly_state = False
        if anomaly_state:
            predict[i] = True
    if calc_latency:
        return predict, latency / (anomaly_count + 1e-4)
    else:
        return predict


def calc_point2point(predict, actual):
    """
    calculate f1 score by predict and actual.
    Args:
            predict (np.ndarray): the predict label
            actual (np.ndarray): np.ndarray
    Method from OmniAnomaly (https://github.com/NetManAIOps/OmniAnomaly)
    """
    TP = np.sum(predict * actual)
    TN = np.sum((1 - predict) * (1 - actual))
    FP = np.sum(predict * (1 - actual))
    FN = np.sum((1 - predict) * actual)
    precision = TP / (TP + FP + 0.00001)
    recall = TP / (TP + FN + 0.00001)
    f1 = 2 * precision * recall / (precision + recall + 0.00001)
    return f1, precision, recall, TP, TN, FP, FN


def pot_eval(init_score, score, label, q=1e-3, level=0.99, dynamic=False):
    """
    Run POT method on given score.
    :param init_score (np.ndarray): The data to get init threshold.
                    For `OmniAnomaly`, it should be the anomaly score of train set.
    :param: score (np.ndarray): The data to run POT method.
                    For `OmniAnomaly`, it should be the anomaly score of test set.
    :param label (np.ndarray): boolean list of true anomalies in score
    :param q (float): Detection level (risk)
    :param level (float): Probability associated with the initial threshold t
    :return dict: pot result dict
    Method from OmniAnomaly (https://github.com/NetManAIOps/OmniAnomaly)
    """

    print(f"Running POT with q={q}, level={level}..")
    s = SPOT(q)  # SPOT object
    s.fit(init_score, score)
    s.initialize(level=level, min_extrema=False)  # Calibration step
    ret = s.run(dynamic=dynamic, with_alarm=False)

    print(len(ret["alarms"]))
    print(len(ret["thresholds"]))

    pot_th = np.mean(ret["thresholds"])
    pred, p_latency = adjust_predicts(score, label, pot_th, calc_latency=True)
    if label is not None:
        p_t = calc_point2point(pred, label)
        return {
            "f1": p_t[0],
            "precision": p_t[1],
            "recall": p_t[2],
            "TP": p_t[3],
            "TN": p_t[4],
            "FP": p_t[5],
            "FN": p_t[6],
            "threshold": pot_th,
            "latency": p_latency,
        }
    else:
        return {
            "threshold": pot_th,
        }


def bf_search(score, label, start, end=None, step_num=1, display_freq=1, verbose=True):
    """
    Find the best-f1 score by searching best `threshold` in [`start`, `end`).
    Method from OmniAnomaly (https://github.com/NetManAIOps/OmniAnomaly)
    """

    print("Finding best f1-score by searching for threshold..")
    if step_num is None or end is None:
        end = start
        step_num = 1
    search_step, search_range, search_lower_bound = step_num, end - start, start
    if verbose:
        print("search range: ", search_lower_bound, search_lower_bound + search_range)
    threshold = search_lower_bound
    m = (-1.0, -1.0, -1.0)
    m_t = 0.0
    m_l = 0
    for i in range(search_step):
        threshold += search_range / float(search_step)
        target, latency = calc_seq(score, label, threshold)
        if target[0] > m[0]:
            m_t = threshold
            m = target
            m_l = latency
        if verbose and i % display_freq == 0:
            print("cur thr: ", threshold, target, m, m_t)

    return {
        "f1": m[0],
        "precision": m[1],
        "recall": m[2],
        "TP": m[3],
        "TN": m[4],
        "FP": m[5],
        "FN": m[6],
        "threshold": m_t,
        "latency": m_l,
    }


def calc_seq(score, label, threshold):
    predict, latency = adjust_predicts(score, label, threshold, calc_latency=True)
    return calc_point2point(predict, label), latency


def epsilon_eval(train_scores, test_scores, test_labels, reg_level=1):
    best_epsilon = find_epsilon(train_scores, reg_level)
    pred, p_latency = adjust_predicts(test_scores, test_labels, best_epsilon, calc_latency=True)
    if test_labels is not None:
        p_t = calc_point2point(pred, test_labels)
        return {
            "f1": p_t[0],
            "precision": p_t[1],
            "recall": p_t[2],
            "TP": p_t[3],
            "TN": p_t[4],
            "FP": p_t[5],
            "FN": p_t[6],
            "threshold": best_epsilon,
            "latency": p_latency,
            "reg_level": reg_level,
        }
    else:
        return {"threshold": best_epsilon, "reg_level": reg_level}


def find_epsilon(errors, reg_level=1):
    """
    Threshold method proposed by Hundman et. al. (https://arxiv.org/abs/1802.04431)
    Code from TelemAnom (https://github.com/khundman/telemanom)
    """
    e_s = errors
    best_epsilon = None
    max_score = -10000000
    mean_e_s = np.mean(e_s)
    sd_e_s = np.std(e_s)

    for z in np.arange(2.5, 12, 0.5):
        epsilon = mean_e_s + sd_e_s * z
        pruned_e_s = e_s[e_s < epsilon]

        i_anom = np.argwhere(e_s >= epsilon).reshape(-1,)
        buffer = np.arange(1, 50)
        i_anom = np.sort(
            np.concatenate(
                (
                    i_anom,
                    np.array([i + buffer for i in i_anom]).flatten(),
                    np.array([i - buffer for i in i_anom]).flatten(),
                )
            )
        )
        i_anom = i_anom[(i_anom < len(e_s)) & (i_anom >= 0)]
        i_anom = np.sort(np.unique(i_anom))

        if len(i_anom) > 0:
            groups = [list(group) for group in mit.consecutive_groups(i_anom)]
            # E_seq = [(g[0], g[-1]) for g in groups if not g[0] == g[-1]]

            mean_perc_decrease = (mean_e_s - np.mean(pruned_e_s)) / mean_e_s
            sd_perc_decrease = (sd_e_s - np.std(pruned_e_s)) / sd_e_s
            if reg_level == 0:
                denom = 1
            elif reg_level == 1:
                denom = len(i_anom)
            elif reg_level == 2:
                denom = len(i_anom) ** 2

            score = (mean_perc_decrease + sd_perc_decrease) / denom

            if score >= max_score and len(i_anom) < (len(e_s) * 0.5):
                max_score = score
                best_epsilon = epsilon

    if best_epsilon is None:
        best_epsilon = np.max(e_s)
    return best_epsilon


def hit_att(ascore, labels, ps=[100, 150]):
    res = {}
    for p in ps:
        hit_score = []
        for i in range(ascore.shape[0]):
            a, l = ascore[i], labels[i]
            a, l = np.argsort(a).tolist()[::-1], set(np.where(l == 1)[0])
            if l:
                size = round(p * len(l) / 100)
                a_p = set(a[:size])
                intersect = a_p.intersection(l)
                hit = len(intersect) / len(l)
                hit_score.append(hit)
        res[f'Hit@{p}%'] = np.mean(hit_score)
    return res


def ndcg(ascore, labels, ps=[100, 150]):
    res = {}
    for p in ps:
        ndcg_scores = []
        for i in range(ascore.shape[0]):
            a, l = ascore[i], labels[i]
            labs = list(np.where(l == 1)[0])
            if labs:
                k_p = round(p * len(labs) / 100)
                try:
                    hit = ndcg_score(l.reshape(1, -1), a.reshape(1, -1), k=k_p)
                except Exception as e:
                    return {e}
                ndcg_scores.append(hit)
        res[f'NDCG@{p}%'] = np.mean(ndcg_scores)
    return res


def CR(ascore, alabel, ks=[8, 16, 20]):
    res = {}
    for k in ks:
        cr_score = []
        for i in range(ascore.shape[0]):
            a = ascore[i]
            l = alabel[i]
            score = np.argsort(a).tolist()[::-1]
            label = set(np.where(l == 1)[0])
            score_k = set(score[:k])
            if label:
                hit = len(score_k.intersection(label))/len(label)
                cr_score.append(hit)
        res[f'CR@{k}%'] = np.mean(cr_score)
    return res


def ER(ascore, alabel, ks=[8, 16, 20]):
    res = {}
    for k in ks:
        er_score = []
        for i in range(ascore.shape[0]):
            a = ascore[i]
            l = alabel[i]
            score = np.argsort(a).tolist()[::-1]
            label = set(np.where(l == 1)[0])
            score_k = set(score[:k])
            if label:
                hit = (k-len(score_k.intersection(label))) / k
                er_score.append(hit)
        res[f'ER@{k}%'] = np.mean(er_score)
    return res


if __name__ == '__main__':
    with open('test_anomaly_scores.txt') as f:
        test_anomaly_scores = np.array([float(line.strip()) for line in f])
    with open('true_anomalies.txt') as f:
        true_anomalies = np.array([float(line.strip()) for line in f])
    with open('train_anomaly_scores.txt') as f:
        train_anomaly_scores = np.array([float(line.strip()) for line in f])

    print(test_anomaly_scores, true_anomalies, train_anomaly_scores)

    epsilon_eval(train_anomaly_scores, test_anomaly_scores, true_anomalies)
```
```learning_adaptation/cgnn/evaluate_prediction.py
import torch

from cgnn.config import set_config, get_config, set_initial_config
from cgnn.utils import create_data_loaders, SlidingWindowDataset
from cgnn.mtad_gat import MTAD_GAT
from cgnn.prediction import Predictor


def predict_and_evaluate(model_config, trained_model, train_array, test_array, anomaly_label_array, save_output=True):
    model_path = f"trained_models_temp/{model_config['dataset']}_{model_config['id']}"

    print(f'Using model from {model_path}')
    set_initial_config()
    set_config(model_config)
    model_config = get_config()
    print(f'Model config: {model_config}')

    window_size = int(model_config['lookback'])
    batch_size = int(model_config['bs'])
    val_split = float(model_config['val_split'])
    shuffle_dataset = (model_config['shuffle_dataset'] == 'True')

    x_train = torch.from_numpy(train_array).float()
    x_test = torch.from_numpy(test_array).float()
    n_features = x_train.shape[1]

    target_dims = None
    out_dim = n_features

    train_dataset = SlidingWindowDataset(x_train, window_size, target_dims)
    test_dataset = SlidingWindowDataset(x_test, window_size, target_dims)

    train_loader, val_loader, test_loader = create_data_loaders(
        train_dataset, batch_size, val_split, shuffle_dataset, test_dataset=test_dataset
    )

    train_dataset = SlidingWindowDataset(x_train, window_size, target_dims)
    test_dataset = SlidingWindowDataset(x_test, window_size, target_dims)

    model = MTAD_GAT(
        n_features,
        window_size,
        out_dim,
        kernel_size=int(model_config['kernel_size']),
        use_gatv2=(model_config['use_gatv2'] == 'True'),
        feat_gat_embed_dim=model_config['feat_gat_embed_dim'],
        time_gat_embed_dim=model_config['time_gat_embed_dim'],
        gru_n_layers=int(model_config['gru_n_layers']),
        gru_hid_dim=int(model_config['gru_hid_dim']),
        forecast_n_layers=int(model_config['fc_n_layers']),
        forecast_hid_dim=int(model_config['fc_hid_dim']),
        dropout=float(model_config['dropout']),
        alpha=float(model_config['alpha'])
    )

    device = "cuda" if (model_config['use_cuda'] == 'True') and torch.cuda.is_available() else "cpu"
    # load(model, trained_model, device=device)
    model.load_state_dict(trained_model)
    model.to(device)

    # # Some suggestions for POT args
    # level_q_dict = {
    #     "SMAP": (0.90, 0.005),
    #     "MSL": (0.90, 0.001),
    #     "SMD-1": (0.9950, 0.001),
    #     "SMD-2": (0.9925, 0.001),
    #     "SMD-3": (0.9999, 0.001)
    # }
    # key = "SMD-" + model_config['group'][0] if model_config['dataset'] == "SMD" else model_config['dataset']
    # level, q = level_q_dict[key]
    # if model_config['level'] is not None:
    #     level = model_config['level']
    # if model_config['q'] is not None:
    #     q = model_config['q']

    # # Some suggestions for Epsilon args
    # reg_level_dict = {"SMAP": 0, "MSL": 0, "SMD-1": 1, "SMD-2": 1, "SMD-3": 1}
    # key = "SMD-" + model_config['group'][0] if model_config['dataset'] == "SMD" else model_config['dataset']
    # reg_level = reg_level_dict[key]


    level = model_config['level']
    q = model_config['q']
    reg_level = model_config['reg_level']

    prediction_args = {
        'dataset': model_config['dataset'],
        "target_dims": target_dims,
        'scale_scores': (model_config['scale_scores'] == 'True'),
        "level": level,
        "q": q,
        'dynamic_pot': (model_config['dynamic_pot'] == 'True'),
        "use_mov_av": (model_config['use_mov_av'] == 'True'),
        "gamma": int(model_config['gamma']),
        "reg_level": reg_level,
        "save_path": model_path,
    }

    summary_file_name = "model_evaluation.json"

    label = anomaly_label_array[window_size:] if anomaly_label_array is not None else None
    predictor = Predictor(model, window_size, n_features, prediction_args, summary_file_name=summary_file_name)

    return predictor.predict_anomalies(x_train, x_test, label, save_output=save_output)

```
```learning_adaptation/cgnn/modules.py
import torch
import torch.nn as nn
import numpy as np


class ConvLayer(nn.Module):
    """1-D Convolution layer to extract high-level features of each time-series input
    :param n_features: Number of input features/nodes
    :param window_size: length of the input sequence
    :param kernel_size: size of kernel to use in the convolution operation
    """

    def __init__(self, n_features, kernel_size=7):
        super(ConvLayer, self).__init__()
        self.padding = nn.ConstantPad1d((kernel_size - 1) // 2, 0.0)
        self.conv = nn.Conv1d(in_channels=n_features, out_channels=n_features, kernel_size=kernel_size)
        self.relu = nn.ReLU()

    def forward(self, x):
        x = x.permute(0, 2, 1)
        x = self.padding(x)
        x = self.relu(self.conv(x))
        return x.permute(0, 2, 1)  # Permute back


def TemporalcorrelationLayer(x):
    use_cuda = True  #
    device = "cuda" if use_cuda and torch.cuda.is_available() else "cpu"
    matrix_all = []
    y = x.data.cpu().numpy()

    for k in range(y.shape[0]):
        data = y[k]
        matrix = np.zeros((data.shape[0], data.shape[0]))
        for i in range(data.shape[0]):
            for j in range(data.shape[1]):
                matrix[i][j] = np.correlate(data[i, :], data[j, :])

        matrix = matrix / data.shape[0]
        matrix_all.append(matrix)
    attention = torch.from_numpy(np.array(matrix_all))
    attention = attention.to(dtype=torch.float32)

    attention = attention.to(device)
    h = torch.sigmoid(torch.matmul(attention, x))  # (b, n, k)

    return h


def FeaturecorrelationLayer(x):
    # print(f'x={x.shape}')
    use_cuda = True  #
    device = "cuda" if use_cuda and torch.cuda.is_available() else "cpu"
    matrix_all = []
    y = x.data.cpu().numpy()

    for k in range(y.shape[0]):
        data = y[k]
        matrix = np.zeros((data.shape[1], data.shape[1]))
        for i in range(data.shape[0]):
            for j in range(data.shape[1]):
                if (i <= j):
                    matrix[i][j] = np.inner(data[:, i], data[:, j])
                else:
                    break
        matrix = matrix / data.shape[0]
        matrix_all.append(matrix)
    attention = torch.from_numpy(np.array(matrix_all))
    attention = attention.to(dtype=torch.float32)
    attention = attention.to(device)
    # print(attention.shape)
    h = torch.sigmoid(torch.matmul(attention, x.permute(0, 2, 1)))
    # print(f'h={h.shape}')
    return h.permute(0, 2, 1)


class GRULayer(nn.Module):
    """Gated Recurrent Unit (GRU) Layer
    :param in_dim: number of input features
    :param hid_dim: hidden size of the GRU
    :param n_layers: number of layers in GRU
    :param dropout: dropout rate
    """

    def __init__(self, in_dim, hid_dim, n_layers, dropout):
        super(GRULayer, self).__init__()
        self.hid_dim = hid_dim
        self.n_layers = n_layers
        self.dropout = 0.0 if n_layers == 1 else dropout
        self.gru = nn.GRU(in_dim, hid_dim, num_layers=n_layers, batch_first=True, dropout=self.dropout)

    def forward(self, x):
        out, h = self.gru(x)
        out, h = out[-1, :, :], h[-1, :, :]  # Extracting from last layer
        return out, h


class Forecasting_Model(nn.Module):
    """Forecasting model (fully-connected network)
    :param in_dim: number of input features
    :param hid_dim: hidden size of the FC network
    :param out_dim: number of output features
    :param n_layers: number of FC layers
    :param dropout: dropout rate
    """

    def __init__(self, in_dim, hid_dim, out_dim, n_layers, dropout):
        super(Forecasting_Model, self).__init__()
        layers = [nn.Linear(in_dim, hid_dim)]

        for _ in range(n_layers - 1):
            layers.append(nn.Linear(hid_dim, hid_dim))

        layers.append(nn.Linear(hid_dim, out_dim))

        self.layers = nn.ModuleList(layers)
        self.dropout = nn.Dropout(dropout)
        self.relu = nn.ReLU()

    def forward(self, x):
        for i in range(len(self.layers) - 1):
            x = self.relu(self.layers[i](x))
            x = self.dropout(x)

        return self.layers[-1](x)


def Denoising(train):
    use_cuda = True
    device = "cuda" if use_cuda and torch.cuda.is_available() else "cpu"

    io_all = []
    for i in range(train.shape[0]):
        data = train[i]
        data = data.data.cpu().numpy()
        io_time = []
        for j in range(data.shape[1]):
            x = data[:, j]
            # x = x.data.cpu().numpy()
            f = np.fft.rfft(x)
            yf_abs = np.abs(f)
            indices = yf_abs > yf_abs.mean()  # filter out those value under 300
            yf_clean = indices * f
            new_f_clean = np.fft.irfft(yf_clean)
            io_time.append(new_f_clean)
        io_time = np.array(io_time)
        io_all.append(io_time)
    io_all = np.array(io_all)
    io_all = torch.from_numpy(np.array(io_all))
    io_all = io_all.to(dtype=torch.float32)
    io_all = io_all.permute(0, 2, 1)
    io_all = io_all.to(device)
    return io_all


class AR(nn.Module):

    def __init__(self, window):
        super(AR, self).__init__()
        self.linear = nn.Linear(window, 1)

    def forward(self, x):
        x = torch.transpose(x, 1, 2)
        x = self.linear(x)
        x = torch.transpose(x, 1, 2)

        return x


class MHSA(nn.Module):
    def __init__(self, num_heads, dim):
        super().__init__()

        self.q = nn.Linear(dim, dim)
        self.k = nn.Linear(dim, dim)
        self.v = nn.Linear(dim, dim)
        self.num_heads = num_heads

    def forward(self, x):
        B, N, C = x.shape
        q = self.q(x).reshape(B, N, self.num_heads, -1).permute(0, 2, 1, 3)
        k = self.k(x).reshape(B, N, self.num_heads, -1).permute(0, 2, 1, 3)
        v = self.k(x).reshape(B, N, self.num_heads, -1).permute(0, 2, 1, 3)

        attn = q @ k.transpose(2, 3) * (x.shape[-1] ** -0.5)
        attn = attn.softmax(dim=-1)
        v = (attn @ v).permute(0, 2, 1, 3).reshape(B, N, C)
        return v
```
```learning_adaptation/cgnn/mtad_gat.py
import torch
import torch.nn as nn
# from test_tube import HyperOptArgumentParser
from cgnn.modules import (
    Denoising,
    ConvLayer,
    GRULayer,
    Forecasting_Model,
    MHSA,
    AR,
    TemporalcorrelationLayer,
    FeaturecorrelationLayer,

)


class MTAD_GAT(nn.Module):
    """ MTAD-GAT model class.

    :param n_features: Number of input features
    :param window_size: Length of the input sequence
    :param out_dim: Number of features to output
    :param kernel_size: size of kernel to use in the 1-D convolution
    :param feat_gat_embed_dim: embedding dimension (output dimension of linear transformation)
           in feat-oriented GAT layer
    :param time_gat_embed_dim: embedding dimension (output dimension of linear transformation)
           in time-oriented GAT layer
    :param use_gatv2: whether to use the modified attention mechanism of GATv2 instead of standard GAT
    :param gru_n_layers: number of layers in the GRU layer
    :param gru_hid_dim: hidden dimension in the GRU layer
    :param forecast_n_layers: number of layers in the FC-based Forecasting Model
    :param forecast_hid_dim: hidden dimension in the FC-based Forecasting Model
    :param recon_n_layers: number of layers in the GRU-based Reconstruction Model
    :param recon_hid_dim: hidden dimension in the GRU-based Reconstruction Model
    :param dropout: dropout rate
    :param alpha: negative slope used in the leaky rely activation function
        d_k (int): d_model / n_head
        d_v (int): d_model / n_head
        d_model (int): outputs of dimension
        n_head (int): num of Multi-head
    """

    def __init__(
        self,
        n_features,
        window_size,
        out_dim,
        kernel_size=7,
        feat_gat_embed_dim=None,
        time_gat_embed_dim=None,
        use_gatv2=True,
        gru_n_layers=1,
        gru_hid_dim=150,
        forecast_n_layers=1,
        forecast_hid_dim=150,
        dropout=0.4,
        alpha=0.2,

    ):
        super(MTAD_GAT, self).__init__()

        self.conv = ConvLayer(n_features, kernel_size)

        self.multiheadattention = MHSA(n_features, 3*n_features)
        self.gru = GRULayer(3 * n_features, gru_hid_dim, gru_n_layers, dropout)

        self.ar = AR(window_size)
        self.forecasting_model = Forecasting_Model(gru_hid_dim, forecast_hid_dim, out_dim, forecast_n_layers, dropout)

    def forward(self, x):
        gamma = 0.5
        x = Denoising(x)
        h_a = self.ar(x)
        h_a = h_a.view(x.shape[0], -1)

        x = self.conv(x)
        h_feat = FeaturecorrelationLayer(x)
        h_temp = TemporalcorrelationLayer(x)
        h_cat = torch.cat([x, h_feat, h_temp], dim=2)  # (b, n, 3k)   (256,100,38*3)
        h_in = self.multiheadattention(h_cat)
        _, h_end = self.gru(h_in)

        h_end = h_end.view(x.shape[0], -1)   # Hidden state for last timestamp
        predictions = self.forecasting_model(h_end)

        predictions_a = gamma*predictions+(1-gamma)*h_a
        return predictions_a
```
```learning_adaptation/cgnn/prediction.py
import json

import numpy as np
import pandas as pd
from tqdm import tqdm
import torch

from cgnn.eval_methods import find_epsilon, epsilon_eval, pot_eval, bf_search, adjust_predicts
from cgnn.utils import SlidingWindowDataset, adjust_anomaly_scores


class Predictor:
    """MTAD-GAT predictor class.

    :param model: MTAD-GAT model (pre-trained) used to forecast and reconstruct
    :param window_size: Length of the input sequence
    :param n_features: Number of input features
    :param pred_args: params for thresholding and predicting anomalies

    """

    def __init__(self, model, window_size, n_features, pred_args, summary_file_name="summary.txt"):
        self.model = model
        self.window_size = window_size
        self.n_features = n_features
        self.dataset = pred_args["dataset"]
        self.target_dims = pred_args["target_dims"]
        self.scale_scores = pred_args["scale_scores"]
        self.q = pred_args["q"]
        self.level = pred_args["level"]
        self.dynamic_pot = pred_args["dynamic_pot"]
        self.use_mov_av = pred_args["use_mov_av"]
        self.gamma = pred_args["gamma"]
        self.reg_level = pred_args["reg_level"]
        self.save_path = pred_args["save_path"]
        self.batch_size = 256
        self.use_cuda = True  #
        self.pred_args = pred_args
        self.summary_file_name = summary_file_name

    def get_score(self, values):
        """Method that calculates anomaly score using given model and data
        :param values: 2D array of multivariate time series data, shape (N, k)
        :return np array of anomaly scores + dataframe with prediction for each channel and global anomalies
        """

        print("Predicting and calculating anomaly scores..")
        data = SlidingWindowDataset(values, self.window_size, self.target_dims)
        loader = torch.utils.data.DataLoader(data, batch_size=self.batch_size, shuffle=False)
        device = "cuda" if self.use_cuda and torch.cuda.is_available() else "cpu"

        self.model.eval()
        preds = []
        with torch.no_grad():
            for x, y in tqdm(loader):
                x = x.to(device)
                y = y.to(device)

                y_hat = self.model(x)

                preds.append(y_hat.detach().cpu().numpy())

        preds = np.concatenate(preds, axis=0)
        actual = values.detach().cpu().numpy()[self.window_size:]

        if self.target_dims is not None:
            actual = actual[:, self.target_dims]

        anomaly_scores = np.zeros_like(actual)
        df = pd.DataFrame()
        for i in range(preds.shape[1]):
            df[f"Forecast_{i}"] = preds[:, i]
            df[f"True_{i}"] = actual[:, i]
            a_score = np.sqrt((preds[:, i] - actual[:, i]) ** 2)

            if self.scale_scores:
                q75, q25 = np.percentile(a_score, [75, 25])
                iqr = q75 - q25
                median = np.median(a_score)
                a_score = (a_score - median) / (1+iqr)

            anomaly_scores[:, i] = a_score
            df[f"A_Score_{i}"] = a_score
        # print(anomaly_scores.shape)
        score = anomaly_scores
        anomaly_scores = np.mean(anomaly_scores, 1)
        df['A_Score_Global'] = anomaly_scores

        return df, score

    def predict_anomalies(self, train, test, true_anomalies, save_output=True):
        """ Predicts anomalies

        :param train: 2D array of train multivariate time series data
        :param test: 2D array of test multivariate time series data
        :param true_anomalies: true anomalies of test set, None if not available
        :param save_scores: Whether to save anomaly scores of train and test
        :param load_scores: Whether to load anomaly scores instead of calculating them
        :param save_output: Whether to save output dataframe
        :param scale_scores: Whether to feature-wise scale anomaly scores
        """

        train_pred_df, _ = self.get_score(train)
        test_pred_df, test_score = self.get_score(test)

        train_anomaly_scores = train_pred_df['A_Score_Global'].values
        test_anomaly_scores = test_pred_df['A_Score_Global'].values
        print("voor adjust", train_anomaly_scores, test_anomaly_scores)
        train_anomaly_scores = adjust_anomaly_scores(train_anomaly_scores, self.dataset, True, self.window_size)
        test_anomaly_scores = adjust_anomaly_scores(test_anomaly_scores, self.dataset, False, self.window_size)
        print("na adjust", train_anomaly_scores, test_anomaly_scores)
        # Update df
        train_pred_df['A_Score_Global'] = train_anomaly_scores
        test_pred_df['A_Score_Global'] = test_anomaly_scores

        if self.use_mov_av:
            smoothing_window = int(self.batch_size * self.window_size * 0.05)
            train_anomaly_scores = pd.DataFrame(train_anomaly_scores).ewm(span=smoothing_window).mean().values.flatten()
            test_anomaly_scores = pd.DataFrame(test_anomaly_scores).ewm(span=smoothing_window).mean().values.flatten()
            print("na mov", train_anomaly_scores, test_anomaly_scores)

        if true_anomalies is not None:
            # Find threshold and predict anomalies at feature-level (for plotting and diagnosis purposes)
            out_dim = self.n_features if self.target_dims is None else len(self.target_dims)
            all_preds = np.zeros((len(test_pred_df), out_dim))
            for i in range(out_dim):
                train_feature_anom_scores = train_pred_df[f"A_Score_{i}"].values
                test_feature_anom_scores = test_pred_df[f"A_Score_{i}"].values
                epsilon = find_epsilon(train_feature_anom_scores, reg_level=2)

                train_feature_anom_preds = (train_feature_anom_scores >= epsilon).astype(int)
                test_feature_anom_preds = (test_feature_anom_scores >= epsilon).astype(int)

                train_pred_df[f"A_Pred_{i}"] = train_feature_anom_preds
                test_pred_df[f"A_Pred_{i}"] = test_feature_anom_preds

                train_pred_df[f"Thresh_{i}"] = epsilon
                test_pred_df[f"Thresh_{i}"] = epsilon

                all_preds[:, i] = test_feature_anom_preds

            # Global anomalies (entity-level) are predicted using aggregation of anomaly scores across all features
            # These predictions are used to evaluate performance, as true anomalies are labeled at entity-level
            # Evaluate using different threshold methods: brute-force, epsilon and peaks-over-treshold
            print("voor eval", train_anomaly_scores, test_anomaly_scores, true_anomalies, len(train_anomaly_scores), len(test_anomaly_scores), len(true_anomalies),)

            e_eval = epsilon_eval(train_anomaly_scores, test_anomaly_scores, true_anomalies, reg_level=self.reg_level)
            p_eval = pot_eval(train_anomaly_scores, test_anomaly_scores, true_anomalies,
                              q=self.q, level=self.level, dynamic=self.dynamic_pot)
            bf_eval = bf_search(test_anomaly_scores, true_anomalies, start=0.01, end=2, step_num=100, verbose=False)
            print(f"Results using epsilon method:\n {e_eval}")
            print(f"Results using peak-over-threshold method:\n {p_eval}")
            print(f"Results using best f1 score search:\n {bf_eval}")

            for k, v in e_eval.items():
                if not type(e_eval[k]) is list:
                    e_eval[k] = float(v)
            for k, v in p_eval.items():
                if not type(p_eval[k]) is list:
                    p_eval[k] = float(v)
            for k, v in bf_eval.items():
                bf_eval[k] = float(v)

            # Save
            summary = {"epsilon_result": e_eval, "pot_result": p_eval, "bf_result": bf_eval}
            with open(f"{self.save_path}/{self.summary_file_name}", "w") as f:
                json.dump(summary, f, indent=2)
        else:
            print("True anomalies are not provided, skipping evaluation steps.")

        # Save anomaly predictions made using epsilon method (could be changed to pot or bf-method)
        if save_output:
            global_epsilon = e_eval["threshold"] if true_anomalies is not None else None
            test_pred_df["A_True_Global"] = true_anomalies
            train_pred_df["Thresh_Global"] = global_epsilon
            test_pred_df["Thresh_Global"] = global_epsilon
            train_pred_df["A_Pred_Global"] = (train_anomaly_scores >= global_epsilon).astype(int)
            test_preds_global = (test_anomaly_scores >= global_epsilon).astype(int)
            # Adjust predictions according to evaluation strategy
            if true_anomalies is not None:
                test_preds_global = adjust_predicts(None, true_anomalies, global_epsilon, pred=test_preds_global)
            test_pred_df["A_Pred_Global"] = test_preds_global

        print("Test scores:", test_score)
        print("-- Done.")

        return summary
```
```learning_adaptation/cgnn/spot.py
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Mon Dec 12 10:08:16 2016
@author: Alban Siffer
@company: Amossys
@license: GNU GPLv3
Code from https://github.com/NetManAIOps/OmniAnomaly
"""
from math import floor, log

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import tqdm
from scipy.optimize import minimize

# colors for plot
deep_saffron = "#FF9933"
air_force_blue = "#5D8AA8"

"""
================================= MAIN CLASS ==================================
"""


class SPOT:
    """
    This class allows to run SPOT algorithm on univariate dataset (upper-bound)

    Attributes
    ----------
    proba : float
            Detection level (risk), chosen by the user

    extreme_quantile : float
            current threshold (bound between normal and abnormal events)

    data : numpy.array
            stream

    init_data : numpy.array
            initial batch of observations (for the calibration/initialization step)

    init_threshold : float
            initial threshold computed during the calibration step

    peaks : numpy.array
            array of peaks (excesses above the initial threshold)

    n : int
            number of observed values

    Nt : int
            number of observed peaks
    """

    def __init__(self, q=1e-4):
        """
        Constructor
        Parameters
        ----------
        q
                Detection level (risk)

        Returns
        ----------
        SPOT object
        """
        self.proba = q
        self.extreme_quantile = None
        self.data = None
        self.init_data = None
        self.init_threshold = None
        self.peaks = None
        self.n = 0
        self.Nt = 0

    def __str__(self):
        s = ""
        s += "Streaming Peaks-Over-Threshold Object\n"
        s += "Detection level q = %s\n" % self.proba
        if self.data is not None:
            s += "Data imported : Yes\n"
            s += "\t initialization  : %s values\n" % self.init_data.size
            s += "\t stream : %s values\n" % self.data.size
        else:
            s += "Data imported : No\n"
            return s

        if self.n == 0:
            s += "Algorithm initialized : No\n"
        else:
            s += "Algorithm initialized : Yes\n"
            s += "\t initial threshold : %s\n" % self.init_threshold

            r = self.n - self.init_data.size
            if r > 0:
                s += "Algorithm run : Yes\n"
                s += "\t number of observations : %s (%.2f %%)\n" % (
                    r,
                    100 * r / self.n,
                )
            else:
                s += "\t number of peaks  : %s\n" % self.Nt
                s += "\t extreme quantile : %s\n" % self.extreme_quantile
                s += "Algorithm run : No\n"
        return s

    def fit(self, init_data, data):
        """
        Import data to SPOT object

        Parameters
        ----------
        init_data : list, numpy.array or pandas.Series
                initial batch to calibrate the algorithm

        data : numpy.array
                data for the run (list, np.array or pd.series)

        """
        if isinstance(data, list):
            self.data = np.array(data)
        elif isinstance(data, np.ndarray):
            self.data = data
        elif isinstance(data, pd.Series):
            self.data = data.values
        else:
            print("This data format (%s) is not supported" % type(data))
            return

        if isinstance(init_data, list):
            self.init_data = np.array(init_data)
        elif isinstance(init_data, np.ndarray):
            self.init_data = init_data
        elif isinstance(init_data, pd.Series):
            self.init_data = init_data.values
        elif isinstance(init_data, int):
            self.init_data = self.data[:init_data]
            self.data = self.data[init_data:]
        elif isinstance(init_data, float) & (init_data < 1) & (init_data > 0):
            r = int(init_data * data.size)
            self.init_data = self.data[:r]
            self.data = self.data[r:]
        else:
            print("The initial data cannot be set")
            return

    def add(self, data):
        """
        This function allows to append data to the already fitted data

        Parameters
        ----------
        data : list, numpy.array, pandas.Series
                data to append
        """
        if isinstance(data, list):
            data = np.array(data)
        elif isinstance(data, np.ndarray):
            data = data
        elif isinstance(data, pd.Series):
            data = data.values
        else:
            print("This data format (%s) is not supported" % type(data))
            return

        self.data = np.append(self.data, data)
        return

    def initialize(self, level=0.98, min_extrema=False, verbose=True):
        """
        Run the calibration (initialization) step

        Parameters
        ----------
        level : float
                (default 0.98) Probability associated with the initial threshold t
        verbose : bool
                (default = True) If True, gives details about the batch initialization
        verbose: bool
                (default True) If True, prints log
        min_extrema bool
                (default False) If True, find min extrema instead of max extrema
        """
        if min_extrema:
            self.init_data = -self.init_data
            self.data = -self.data
            level = 1 - level

        level = level - floor(level)

        n_init = self.init_data.size

        S = np.sort(self.init_data)  # we sort X to get the empirical quantile
        self.init_threshold = S[int(level * n_init)]  # t is fixed for the whole algorithm

        # initial peaks
        self.peaks = self.init_data[self.init_data > self.init_threshold] - self.init_threshold
        self.Nt = self.peaks.size
        self.n = n_init

        if verbose:
            print("Initial threshold : %s" % self.init_threshold)
            print("Number of peaks : %s" % self.Nt)
            print("Grimshaw maximum log-likelihood estimation ... ", end="")

        g, s, l = self._grimshaw()
        self.extreme_quantile = self._quantile(g, s)

        if verbose:
            print("[done]")
            print("\t" + chr(0x03B3) + " = " + str(g))
            print("\t" + chr(0x03C3) + " = " + str(s))
            print("\tL = " + str(l))
            print("Extreme quantile (probability = %s): %s" % (self.proba, self.extreme_quantile))

        return

    def _rootsFinder(fun, jac, bounds, npoints, method):
        """
        Find possible roots of a scalar function

        Parameters
        ----------
        fun : function
                scalar function
        jac : function
                first order derivative of the function
        bounds : tuple
                (min,max) interval for the roots search
        npoints : int
                maximum number of roots to output
        method : str
                'regular' : regular sample of the search interval, 'random' : uniform (distribution) sample of the search interval

        Returns
        ----------
        numpy.array
                possible roots of the function
        """
        if method == "regular":
            step = (bounds[1] - bounds[0]) / (npoints + 1)
            X0 = np.arange(bounds[0] + step, bounds[1], step)
        elif method == "random":
            X0 = np.random.uniform(bounds[0], bounds[1], npoints)

        def objFun(X, f, jac):
            g = 0
            j = np.zeros(X.shape)
            i = 0
            for x in X:
                fx = f(x)
                g = g + fx ** 2
                j[i] = 2 * fx * jac(x)
                i = i + 1
            return g, j

        opt = minimize(
            lambda X: objFun(X, fun, jac),
            X0,
            method="L-BFGS-B",
            jac=True,
            bounds=[bounds] * len(X0),
        )

        X = opt.x
        np.round(X, decimals=5)
        return np.unique(X)

    def _log_likelihood(Y, gamma, sigma):
        """
        Compute the log-likelihood for the Generalized Pareto Distribution (=0)

        Parameters
        ----------
        Y : numpy.array
                observations
        gamma : float
                GPD index parameter
        sigma : float
                GPD scale parameter (>0)
        Returns
        ----------
        float
                log-likelihood of the sample Y to be drawn from a GPD(,,=0)
        """
        n = Y.size
        if gamma != 0:
            tau = gamma / sigma
            L = -n * log(sigma) - (1 + (1 / gamma)) * (np.log(1 + tau * Y)).sum()
        else:
            L = n * (1 + log(Y.mean()))
        return L

    def _grimshaw(self, epsilon=1e-8, n_points=10):
        """
        Compute the GPD parameters estimation with the Grimshaw's trick

        Parameters
        ----------
        epsilon : float
                numerical parameter to perform (default : 1e-8)
        n_points : int
                maximum number of candidates for maximum likelihood (default : 10)
        Returns
        ----------
        gamma_best,sigma_best,ll_best
                gamma estimates, sigma estimates and corresponding log-likelihood
        """

        def u(s):
            return 1 + np.log(s).mean()

        def v(s):
            return np.mean(1 / s)

        def w(Y, t):
            s = 1 + t * Y
            us = u(s)
            vs = v(s)
            return us * vs - 1

        def jac_w(Y, t):
            s = 1 + t * Y
            us = u(s)
            vs = v(s)
            jac_us = (1 / t) * (1 - vs)
            jac_vs = (1 / t) * (-vs + np.mean(1 / s ** 2))
            return us * jac_vs + vs * jac_us

        Ym = self.peaks.min()
        YM = self.peaks.max()
        Ymean = self.peaks.mean()

        a = -1 / YM
        if abs(a) < 2 * epsilon:
            epsilon = abs(a) / n_points

        a = a + epsilon
        b = 2 * (Ymean - Ym) / (Ymean * Ym)
        c = 2 * (Ymean - Ym) / (Ym ** 2)

        # We look for possible roots
        left_zeros = SPOT._rootsFinder(
            lambda t: w(self.peaks, t),
            lambda t: jac_w(self.peaks, t),
            (a + epsilon, -epsilon),
            n_points,
            "regular",
        )

        right_zeros = SPOT._rootsFinder(
            lambda t: w(self.peaks, t),
            lambda t: jac_w(self.peaks, t),
            (b, c),
            n_points,
            "regular",
        )

        # all the possible roots
        zeros = np.concatenate((left_zeros, right_zeros))

        # 0 is always a solution so we initialize with it
        gamma_best = 0
        sigma_best = Ymean
        ll_best = SPOT._log_likelihood(self.peaks, gamma_best, sigma_best)

        # we look for better candidates
        for z in zeros:
            gamma = u(1 + z * self.peaks) - 1
            sigma = gamma / z
            ll = SPOT._log_likelihood(self.peaks, gamma, sigma)
            if ll > ll_best:
                gamma_best = gamma
                sigma_best = sigma
                ll_best = ll

        return gamma_best, sigma_best, ll_best

    def _quantile(self, gamma, sigma):
        """
        Compute the quantile at level 1-q

        Parameters
        ----------
        gamma : float
                GPD parameter
        sigma : float
                GPD parameter
        Returns
        ----------
        float
                quantile at level 1-q for the GPD(,,=0)
        """
        r = self.n * self.proba / self.Nt
        if gamma != 0:
            return self.init_threshold + (sigma / gamma) * (pow(r, -gamma) - 1)
        else:
            return self.init_threshold - sigma * log(r)

    def run(self, with_alarm=True, dynamic=True):
        """
        Run SPOT on the stream

        Parameters
        ----------
        with_alarm : bool
            (default = True) If False, SPOT will adapt the threshold assuming \
            there is no abnormal values
        Returns
        ----------
        dict
            keys : 'thresholds' and 'alarms'

            'thresholds' contains the extreme quantiles and 'alarms' contains \
            the indexes of the values which have triggered alarms

        """
        if self.n > self.init_data.size:
            print(
                "Warning : the algorithm seems to have already been run, you \
            should initialize before running again"
            )
            return {}

        # list of the thresholds
        th = []
        alarm = []
        # Loop over the stream
        for i in tqdm.tqdm(range(self.data.size)):

            if not dynamic:
                if self.data[i] > self.init_threshold and with_alarm:
                    self.extreme_quantile = self.init_threshold
                    alarm.append(i)
            else:
                # If the observed value exceeds the current threshold (alarm case)
                if self.data[i] > self.extreme_quantile:
                    # if we want to alarm, we put it in the alarm list
                    if with_alarm:
                        alarm.append(i)
                    # otherwise we add it in the peaks
                    else:
                        self.peaks = np.append(self.peaks, self.data[i] - self.init_threshold)
                        # self.peaks = self.peaks[1:]
                        self.Nt += 1
                        self.n += 1
                        # and we update the thresholds

                        g, s, l = self._grimshaw()
                        self.extreme_quantile = self._quantile(g, s)

                # case where the value exceeds the initial threshold but not the alarm ones
                elif self.data[i] > self.init_threshold:
                    # we add it in the peaks
                    self.peaks = np.append(self.peaks, self.data[i] - self.init_threshold)
                    # self.peaks = self.peaks[1:]
                    self.Nt += 1
                    self.n += 1
                    # and we update the thresholds

                    g, s, l = self._grimshaw()
                    self.extreme_quantile = self._quantile(g, s)
                else:
                    self.n += 1

            th.append(self.extreme_quantile)  # thresholds record

        return {"thresholds": th, "alarms": alarm}

    def plot(self, run_results, with_alarm=True):
        """
        Plot the results of given by the run

        Parameters
        ----------
        run_results : dict
                results given by the 'run' method
        with_alarm : bool
                (default = True) If True, alarms are plotted.
        Returns
        ----------
        list
                list of the plots

        """
        x = range(self.data.size)
        K = run_results.keys()

        (ts_fig,) = plt.plot(x, self.data, color=air_force_blue)
        fig = [ts_fig]

        if "thresholds" in K:
            th = run_results["thresholds"]
            (th_fig,) = plt.plot(x, th, color=deep_saffron, lw=2, ls="dashed")
            fig.append(th_fig)

        if with_alarm and ("alarms" in K):
            alarm = run_results["alarms"]
            al_fig = plt.scatter(alarm, self.data[alarm], color="red")
            fig.append(al_fig)

        plt.xlim((0, self.data.size))

        return fig


"""
============================ UPPER & LOWER BOUNDS =============================
"""
```
```learning_adaptation/cgnn/train.py
import json
from datetime import datetime
import torch.nn as nn
import torch
import os

from cgnn.config import set_initial_config, set_config, get_config
from cgnn.utils import SlidingWindowDataset, create_data_loaders
from cgnn.mtad_gat import MTAD_GAT
from cgnn.training import Trainer


def train(dataset_config, train_array, test_array, anomaly_label_array):
    id = datetime.now().strftime("%d%m%Y_%H%M%S")
    set_initial_config()
    set_config(dataset_config)
    config = get_config()
    config['id'] = id

    n_epochs = config['epochs']
    window_size = config['lookback']
    batch_size = config['bs']
    init_lr = config['init_lr']
    val_split = config['val_split']
    shuffle_dataset = config['shuffle_dataset']
    use_cuda = config['use_cuda']
    print_every = config['print_every']
    log_tensorboard = config['log_tensorboard']
    print(config)

    save_path = f"trained_models_temp/{config['dataset']}_{id}"
    if not os.path.exists(save_path):
        os.makedirs(save_path)

    x_train = torch.from_numpy(train_array).float()
    x_test = torch.from_numpy(test_array).float()
    n_features = x_train.shape[1]

    target_dims = None
    out_dim = n_features

    train_dataset = SlidingWindowDataset(x_train, window_size, target_dims)
    test_dataset = SlidingWindowDataset(x_test, window_size, target_dims)

    train_loader, val_loader, test_loader = create_data_loaders(
        train_dataset, batch_size, val_split, shuffle_dataset, test_dataset=test_dataset
    )

    model = MTAD_GAT(
        n_features,
        window_size,
        out_dim,
        kernel_size=config['kernel_size'],
        use_gatv2=config['use_gatv2'],
        feat_gat_embed_dim=config['feat_gat_embed_dim'],
        time_gat_embed_dim=config['time_gat_embed_dim'],
        gru_n_layers=config['gru_n_layers'],
        gru_hid_dim=config['gru_hid_dim'],
        forecast_n_layers=config['fc_n_layers'],
        forecast_hid_dim=config['fc_hid_dim'],
        dropout=config['dropout'],
        alpha=config['alpha']
    )

    optimizer = torch.optim.Adam(model.parameters(), lr=config['init_lr'])
    forecast_criterion = nn.MSELoss()

    args_summary = json.dumps(config, indent=2)

    trainer = Trainer(
        model,
        optimizer,
        window_size,
        n_features,
        target_dims,
        n_epochs,
        batch_size,
        init_lr,
        forecast_criterion,
        use_cuda,
        save_path,
        print_every,
        log_tensorboard,
        args_summary
    )

    trainer.fit(train_loader, val_loader)

    # Check test loss
    test_loss = trainer.evaluate(test_loader)
    print(f"Test forecast loss: {test_loss[0]:.5f}")
    print(f"Test total loss: {test_loss[1]:.5f}")

    trainer.load(f"{save_path}/model.pt")

    print(anomaly_label_array) if anomaly_label_array is not None else None
    label = anomaly_label_array[window_size:] if anomaly_label_array is not None else None

    print(x_train, x_test, label)
    print(config)

    with open(f"{save_path}/model_config.json", "w") as f:
        json.dump(config, f, indent=2)

    print(trainer.losses)

    return trainer, config
```
```learning_adaptation/cgnn/training.py
import os
import time
import numpy as np
import torch
import torch.nn as nn
from tqdm import tqdm


class Trainer:
    """Trainer class for MTAD-GAT model.

    :param model: MTAD-GAT model
    :param optimizer: Optimizer used to minimize the loss function
    :param window_size: Length of the input sequence
    :param n_features: Number of input features
    :param target_dims: dimension of input features to forecast and reconstruct
    :param n_epochs: Number of iterations/epochs
    :param batch_size: Number of windows in a single batch
    :param init_lr: Initial learning rate of the module
    :param forecast_criterion: Loss to be used for forecasting.
    :param recon_criterion: Loss to be used for reconstruction.
    :param boolean use_cuda: To be run on GPU or not
    :param dload: Download directory where models are to be dumped
    :param log_dir: Directory where SummaryWriter logs are written to
    :param print_every: At what epoch interval to print losses
    :param log_tensorboard: Whether to log loss++ to tensorboard
    :param args_summary: Summary of args that will also be written to tensorboard if log_tensorboard
    """

    def __init__(
        self,
        model,
        optimizer,
        window_size,
        n_features,
        target_dims=None,
        n_epochs=200,
        batch_size=256,
        init_lr=0.001,
        forecast_criterion=nn.MSELoss(),
        use_cuda=True,
        dload="",
        print_every=1,
        log_tensorboard=True,
        args_summary="",
    ):

        self.model = model
        self.optimizer = optimizer
        self.window_size = window_size
        self.n_features = n_features
        self.target_dims = target_dims
        self.n_epochs = n_epochs
        self.batch_size = batch_size
        self.init_lr = init_lr
        self.forecast_criterion = forecast_criterion
        self.device = "cuda" if use_cuda and torch.cuda.is_available() else "cpu"
        print(self.device)
        self.dload = dload
        self.print_every = print_every
        self.log_tensorboard = log_tensorboard

        self.losses = {
            "train_total": [],
            "train_forecast": [],
            "train_recon": [],
            "val_total": [],
            "val_forecast": [],

        }
        self.epoch_times = []

        if self.device == "cuda":
            self.model.cuda()


    def fit(self, train_loader, val_loader=None):
        """Train model for self.n_epochs.
        Train and validation (if validation loader given) losses stored in self.losses

        :param train_loader: train loader of input data
        :param val_loader: validation loader of input data
        """

        init_train_loss = self.evaluate(train_loader)
        print(f"Init total train loss: {init_train_loss[1]:5f}")

        if val_loader is not None:
            init_val_loss = self.evaluate(val_loader)
            print(f"Init total val loss: {init_val_loss[1]:.5f}")

        print(f"Training model for {self.n_epochs} epochs..")

        train_start = time.time()
        for epoch in tqdm(range(self.n_epochs)):
            epoch_start = time.time()
            self.model.train()
            forecast_b_losses = []

            for x, y in tqdm(train_loader):

                x = x.to(self.device)
                y = y.to(self.device)
                self.optimizer.zero_grad()

                preds = self.model(x)

                if self.target_dims is not None:
                    x = x[:, :, self.target_dims]
                    y = y[:, :, self.target_dims].squeeze(-1)

                if preds.ndim == 3:
                    preds = preds.squeeze(1)
                if y.ndim == 3:
                    y = y.squeeze(1)

                forecast_loss = torch.sqrt(self.forecast_criterion(y, preds))
                loss = forecast_loss
                loss.backward()
                self.optimizer.step()

                forecast_b_losses.append(forecast_loss.item())

            forecast_b_losses = np.array(forecast_b_losses)

            forecast_epoch_loss = np.sqrt((forecast_b_losses ** 2).mean())

            total_epoch_loss = forecast_epoch_loss
            self.losses["train_forecast"].append(forecast_epoch_loss)
            self.losses["train_total"].append(total_epoch_loss)

            # Evaluate on validation set
            forecast_val_loss, total_val_loss = "NA", "NA"
            if val_loader is not None:

                forecast_val_loss, total_val_loss = self.evaluate(val_loader)
                self.losses["val_forecast"].append(forecast_val_loss)
                self.losses["val_total"].append(total_val_loss)

                if total_val_loss <= self.losses["val_total"][-1]:
                    self.save("model.pt")

            if self.log_tensorboard:
                self.write_loss(epoch)

            epoch_time = time.time() - epoch_start
            self.epoch_times.append(epoch_time)

            if epoch % self.print_every == 0:
                s = (
                    f"[Epoch {epoch + 1}] "
                    f"forecast_loss = {forecast_epoch_loss:.5f}, "
                    f"total_loss = {total_epoch_loss:.5f}"
                )

                if val_loader is not None:
                    s += (
                        f" ---- val_forecast_loss = {forecast_val_loss:.5f}, "
                        f"val_total_loss = {total_val_loss:.5f}"
                    )

                s += f" [{epoch_time:.1f}s]"
                print(s)

        if val_loader is None:
            self.save("model.pt")

        train_time = int(time.time() - train_start)
        if self.log_tensorboard:
            self.writer.add_text("total_train_time", str(train_time))
        print(f"-- Training done in {train_time}s.")

    def evaluate(self, data_loader):
        """Evaluate model

        :param data_loader: data loader of input data
        :return forecasting loss, reconstruction loss, total loss
        """

        self.model.eval()

        forecast_losses = []
        with torch.no_grad():
            for x, y in tqdm(data_loader):
                x = x.to(self.device)
                y = y.to(self.device)

                preds = self.model(x)

                if self.target_dims is not None:
                    x = x[:, :, self.target_dims]
                    y = y[:, :, self.target_dims].squeeze(-1)

                if preds.ndim == 3:
                    preds = preds.squeeze(1)
                if y.ndim == 3:
                    y = y.squeeze(1)

                forecast_loss = torch.sqrt(self.forecast_criterion(y, preds))

                forecast_losses.append(forecast_loss.item())

        forecast_losses = np.array(forecast_losses)

        forecast_loss = np.sqrt((forecast_losses ** 2).mean())

        total_loss = forecast_loss

        return forecast_loss,  total_loss

    def save(self, file_name):
        """
        Pickles the model parameters to be retrieved later
        :param file_name: the filename to be saved as,`dload` serves as the download directory
        """
        PATH = self.dload + "/" + file_name
        if os.path.exists(self.dload):
            pass
        else:
            os.mkdir(self.dload)
        torch.save(self.model.state_dict(), PATH)

    def load(self, PATH):
        """
        Loads the model's parameters from the path mentioned
        :param PATH: Should contain pickle file
        """
        self.model.load_state_dict(torch.load(PATH, map_location=self.device))

    def write_loss(self, epoch):
        for key, value in self.losses.items():
            if len(value) != 0:
                self.writer.add_scalar(key, value[-1], epoch)
```
```learning_adaptation/cgnn/utils.py
import numpy as np
import torch
from torch.utils.data import DataLoader, Dataset, SubsetRandomSampler


class SlidingWindowDataset(Dataset):
    def __init__(self, data, window, target_dim=None, horizon=1):
        self.data = data
        self.window = window
        self.target_dim = target_dim
        self.horizon = horizon

    def __getitem__(self, index):
        x = self.data[index: index + self.window]
        y = self.data[index + self.window: index + self.window + self.horizon]
        return x, y

    def __len__(self):
        return len(self.data) - self.window


def create_data_loaders(train_dataset, batch_size, val_split=0.1, shuffle=True, test_dataset=None):
    train_loader, val_loader, test_loader = None, None, None
    if val_split == 0.0:
        print(f"train_size: {len(train_dataset)}")
        train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle)

    else:
        dataset_size = len(train_dataset)
        indices = list(range(dataset_size))
        split = int(np.floor(val_split * dataset_size))
        if shuffle:
            np.random.shuffle(indices)
        train_indices, val_indices = indices[split:], indices[:split]

        train_sampler = SubsetRandomSampler(train_indices)
        valid_sampler = SubsetRandomSampler(val_indices)

        train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler)
        val_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, sampler=valid_sampler)

        print(f"train_size: {len(train_indices)}")
        print(f"validation_size: {len(val_indices)}")

    if test_dataset is not None:
        test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)
        print(f"test_size: {len(test_dataset)}")

    return train_loader, val_loader, test_loader


def load(model, trained_model, device="cpu"):
    """
    Loads the model's parameters from the trained model
    """
    model.load_state_dict(torch.load(trained_model, map_location=device))


def adjust_anomaly_scores(scores, dataset, is_train, lookback):
    """
    Method for MSL and SMAP where channels have been concatenated as part of the preprocessing
    :param scores: anomaly_scores
    :param dataset: name of dataset
    :param is_train: if scores is from train set
    :param lookback: lookback (window size) used in model
    """

    # Remove errors for time steps when transition to new channel (as this will be impossible for model to predict)
    if dataset.upper() not in ['SMAP', 'MSL']:
        return scores

    adjusted_scores = scores.copy()
    if is_train:
        md = pd.read_csv(f'./datasets/data/{dataset.lower()}_train_md.csv')
    else:
        md = pd.read_csv('./datasets/data/labeled_anomalies.csv')
        md = md[md['spacecraft'] == dataset.upper()]

    md = md[md['chan_id'] != 'P-2']

    # Sort values by channel
    md = md.sort_values(by=['chan_id'])

    # Getting the cumulative start index for each channel
    sep_cuma = np.cumsum(md['num_values'].values) - lookback
    sep_cuma = sep_cuma[:-1]
    buffer = np.arange(1, 20)
    i_remov = np.sort(np.concatenate((sep_cuma, np.array([i+buffer for i in sep_cuma]).flatten(),
                                      np.array([i-buffer for i in sep_cuma]).flatten())))
    i_remov = i_remov[(i_remov < len(adjusted_scores)) & (i_remov >= 0)]
    i_remov = np.sort(np.unique(i_remov))
    if len(i_remov) != 0:
        adjusted_scores[i_remov] = 0

    # Normalize each concatenated part individually
    sep_cuma = np.cumsum(md['num_values'].values) - lookback
    s = [0] + sep_cuma.tolist()
    for c_start, c_end in [(s[i], s[i+1]) for i in range(len(s)-1)]:
        e_s = adjusted_scores[c_start: c_end+1]

        e_s = (e_s - np.min(e_s))/(np.max(e_s) - np.min(e_s))
        adjusted_scores[c_start: c_end+1] = e_s

    return adjusted_scores
```

```user_interface/monitoring_project/config_app/urls.py
from django.urls import path
from .views.home import home
from .views.update_config import config, config_cgnn, config_crca, config_cgnn_train
from .views.training import train_algorithms, train_cgnn, upload_cgnn_train_data, cgnn_train_data
from .views.anomaly_detection import (home_anomaly_detection, perform_anomaly_detection_cgnn, perform_anomaly_detection_crca,
                                      select_crca_file, chosen_crca, upload_cgnn_data, upload_crca_data)
from .views.monitoring import monitoring, monitoring_home, monitoring_overview, task_manager
from .views.api import get_settings
from .views.task_results import get_results, training_result

urlpatterns = [
    path('', home, name='home'),

    path('config/', config, name='config'),
    path('config-cgnn/', config_cgnn, name='config_cgnn'),
    path('config-crca/', config_crca, name='config_crca'),
    path('config-cgnn-train/', config_cgnn_train, name='config_cgnn_train'),
    path('results/<task_id>/<task_type>', get_results, name='get_results'),

    path('train-algorithms/', train_algorithms, name='train_algorithms'),
    path('train-cgnn/', train_cgnn, name='train_cgnn'),
    path('upload-cgnn-train-data/', upload_cgnn_train_data, name='upload_cgnn_train_data'),
    path('cgnn-train-data/', cgnn_train_data, name='cgnn_train_data'),
    path('training-result', training_result, name='training_result'),

    path('home-anomaly-detection/', home_anomaly_detection, name='home_anomaly_detection'),
    path('perform-anomaly-detection-crca/', perform_anomaly_detection_crca, name='perform_anomaly_detection_crca'),
    path('select-crca-file/', select_crca_file, name='select_crca_file'),
    path('chosen-crca/', chosen_crca, name='chosen_crca'),
    path('upload-crca-data/', upload_crca_data, name='upload_crca_data'),

    path('perform-anomaly-detection-cgnn/', perform_anomaly_detection_cgnn, name='perform_anomaly_detection_cgnn'),
    path('upload-cgnn-data/', upload_cgnn_data, name='upload_cgnn_data'),

    path('monitoring-home/', monitoring_home, name='monitoring_home'),
    path('monitoring/', monitoring, name='monitoring'),
    path('monitoring-overview/', monitoring_overview, name='monitoring_overview'),
    path('task_manager/', task_manager, name='task_manager'),

    path('api/settings/', get_settings, name='get_settings'),

]
```
```user_interface/monitoring_project/config_app/model.py
from django.db import models


class RCAData(models.Model):
    metrics = models.TextField()
    image_data = models.TextField(null=True)
    created_at = models.DateTimeField(auto_now_add=True)

```
```user_interface/monitoring_project/config_app/forms.py
from django import forms


def create_dynamic_form(config_data):
    class ConfigForm(forms.Form):
        pass

    for key, value in config_data.items():
        field_type = forms.CharField  # Default to CharField
        if isinstance(value, bool):
            field_type = forms.BooleanField
        elif isinstance(value, int):
            field_type = forms.IntegerField
        elif isinstance(value, float):
            field_type = forms.FloatField

        field = field_type(initial=value, required=False)
        ConfigForm.base_fields[key] = field

    return ConfigForm


class FileUploadForm(forms.Form):
    file = forms.FileField()


class MonitoringForm(forms.Form):
    containers = forms.MultipleChoiceField(widget=forms.CheckboxSelectMultiple, choices=[], label='Containers', required=True, help_text="Select containers to monitor (should match the number of containers in the model)")
    model = forms.ChoiceField(choices=[], label='Model', required=True)
    data_interval = forms.IntegerField(min_value=1, required=True, initial=5, help_text="Measurement Interval in Seconds")
    duration = forms.IntegerField(min_value=10, required=True, initial=10, help_text="Test Duration in Minutes (> 30 minutes recommended)")
    test_interval = forms.FloatField(min_value=0.1, required=True, initial=5, help_text="Test Interval in Minutes (> 5 minutes recommended)")
    crca_threshold = forms.FloatField(min_value=0.0, required=True, initial=0.5, help_text="Threshold of Anomalies detected in Percentages to trigger RCA")
    crca_pods = forms.MultipleChoiceField(widget=forms.CheckboxSelectMultiple, choices=[], label='Crca Containers', required=True, help_text="Select containers to perform CRCA on if threshold is triggered (can be any number)")


class UploadCGNNTrainDataForm(forms.Form):
    train_array = forms.FileField(label='Train Array')
    test_array = forms.FileField(label='Test Array')
    anomaly_label_array = forms.FileField(label='Anomaly Label Array')
    anomaly_sequence = forms.BooleanField(label='Does this contain an Anomaly Sequence?', required=False)
    dataset = forms.CharField(label='Name Your Dataset', max_length=100)
    comment = forms.CharField(label='Comment', max_length=255, required=False)
    metrics = forms.MultipleChoiceField(
        choices=[],
        widget=forms.CheckboxSelectMultiple,
        label='Select Metrics'
    )
    ordered_metrics = forms.CharField(widget=forms.HiddenInput(), required=False)

```
```user_interface/monitoring_project/config_app/views/anomaly_detection.py
import requests
import pandas as pd
from django.shortcuts import render, redirect
from django.contrib import messages
from django.conf import settings
from requests.exceptions import RequestException
from io import StringIO
import json

from .utils import get_config, get_pods, get_available_models, get_settings, get_metrics


def home_anomaly_detection(request):
    return render(request, 'config_app/anomaly_detection/home_anomaly_detection.html')


def perform_anomaly_detection_cgnn(request):
    config_data = get_config(settings.API_CGNN_ANOMALY_DETECTION_URL)
    return render(request, 'config_app/anomaly_detection/cgnn/cgnn_anomaly_detection_home.html', {'config': config_data})


def perform_anomaly_detection_crca(request):
    config_data = get_config(settings.API_CRCA_ANOMALY_DETECTION_URL)
    return render(request, 'config_app/anomaly_detection/crca/crca_anomaly_detection_home.html', {'config': config_data})


def select_crca_file(request):
    pod_names_url = get_pods(settings.CLUSTER_NAMESPACE)
    try:
        response = requests.get(pod_names_url)
        response.raise_for_status()
        pod_names_data = response.json()
    except RequestException as e:
        pod_names_data = []
        messages.error(request, f'Failed to retrieve pod names: {str(e)}')
    return render(request, 'config_app/anomaly_detection/crca/crca_select_file.html', {'pod_names': pod_names_data})


def chosen_crca(request):
    if request.method == 'POST':
        selected_pod_names = request.POST.getlist('selected_pod_names')
        start_datetime = request.POST.get('start_datetime')
        end_datetime = request.POST.get('end_datetime')
        data = {
            'pod_names': selected_pod_names,
            'start_datetime': start_datetime,
            'end_datetime': end_datetime
        }
        try:
            response = requests.post(f'{settings.API_DATA_PROCESSING_URL}/crca_uploaded_by_user', json=data)
            response.raise_for_status()
            response_data = response.json()
            graph_images = response_data['graph_image']
            csv_data = response_data['file']
            csv_df = pd.read_csv(StringIO(csv_data))
            context = {
                'message': response_data['message'],
                'graph_images': graph_images,
                'csv_data': csv_df.to_html(classes='table table-striped', index=False)
            }
            return render(request, 'config_app/anomaly_detection/crca/display_crca_response.html', context)
        except requests.RequestException as e:
            messages.error(request, f'Failed to process data: {str(e)}')
            return redirect('select_crca_file')
    return redirect('select_crca_file')


def upload_cgnn_data(request):
    models = {}
    selected_model = None
    result = None

    models = get_available_models(settings.API_CGNN_ANOMALY_DETECTION_URL)

    if request.method == 'POST':
        selected_model = request.POST.get('selected_model')
        data_file = request.FILES.get('data_file')
        test_info = {
            'settings': get_settings(),
            'data': {'model': selected_model}
        }
        test_info_json = json.dumps(test_info)
        if selected_model and data_file:
            try:
                response = requests.post(f'{settings.API_DATA_PROCESSING_URL}/preprocess_cgnn_data',
                                         files={'test_array': data_file}, data={'test_info': test_info_json})
                response.raise_for_status()
                result = response.json()
            except requests.RequestException as e:
                messages.error(request, f'Failed to perform anomaly detection: {str(e)}')

    context = {
        'models': models,
        'selected_model': selected_model,
        'result': result,
    }
    return render(request, 'config_app/anomaly_detection/cgnn/cgnn_upload_data.html', context)


def upload_crca_data(request):
    if request.method == 'POST':
        crca_file = request.FILES['crca_file']
        metrics = json.loads(request.POST.get('selected_metrics', '[]'))
        containers = json.loads(request.POST.get('containers', '[]'))

        crca_data = {
            'metrics': metrics,
            'containers': containers
        }
        crca_info = {
            'settings': get_settings(),
            'data': crca_data
        }
        crca_info_json = json.dumps(crca_info)
        try:
            response = requests.post(f'{settings.API_DATA_PROCESSING_URL}/preprocess_crca_data',
                                     files={'crca_file': crca_file}, data={'crca_info': crca_info_json})
            response_data = response.json()
            task_id = response_data.get('task_id')

            return render(request, 'config_app/waiting_page.html', {'task_id': task_id,
                                                                    'api_url': settings.API_CRCA_ANOMALY_DETECTION_URL,
                                                                    'task_type': 'crca'})

        except RequestException as e:
            messages.error(request, f'Failed to upload file: {str(e)}')
            return redirect('home')

    metrics = get_metrics()
    return render(request, 'config_app/anomaly_detection/crca/crca_upload_data.html', {'metrics': metrics})
```
```user_interface/monitoring_project/config_app/views/home.py
from django.shortcuts import render
from .utils import get_settings


def home(request):
    config_data = get_settings()
    return render(request, 'config_app/home.html', {'config': config_data})
```
```user_interface/monitoring_project/config_app/views/monitoring.py
import requests
from requests.exceptions import RequestException
from django.shortcuts import render
from ..forms import MonitoringForm, create_dynamic_form
from .utils import get_pods, get_available_models, get_config
from django.conf import settings
from django.http import JsonResponse
import json

from .utils import get_settings


def monitoring_home(request):
    load_kube_config()
    pod_names = get_pods(settings.CLUSTER_NAMESPACE)
    return render(request, 'config_app/monitoring/monitoring_home.html', {'pod_names': pod_names})


def monitoring(request):
    load_kube_config()
    config_data = get_config(settings.API_CRCA_ANOMALY_DETECTION_URL)
    crca_form = create_dynamic_form(config_data)()

    if request.method == 'POST':
        pods = get_pods(settings.CLUSTER_NAMESPACE)
        pod_choices = [(pod, pod) for pod in pods]
        model_choices = get_available_models(settings.API_CGNN_ANOMALY_DETECTION_URL)
        form = MonitoringForm(request.POST)
        form.fields['containers'].choices = pod_choices
        form.fields['model'].choices = [(model, model) for model in model_choices]
        form.fields['crca_pods'].choices = pod_choices

        if form.is_valid():
            containers = form.cleaned_data['containers']
            selected_model = form.cleaned_data['model']
            data_interval = form.cleaned_data['data_interval']
            duration = form.cleaned_data['duration']
            test_interval = form.cleaned_data['test_interval']
            crca_threshold = form.cleaned_data['crca_threshold']
            crca_pods = form.cleaned_data['crca_pods']
            crca_config = json.loads(request.POST.get('crca_config_data', '{}'))

            monitor_data = {
                'metrics': model_choices[selected_model]['model_params']['metrics'],
                'containers': containers,
                'data_interval': data_interval,
                'duration': duration,
                'test_interval': test_interval,
                'model': selected_model,
                'crca_threshold': crca_threshold,
                'crca_pods': crca_pods,
                'crca_config': crca_config
            }
            monitor_info = {
                'settings': get_settings(),
                'data': monitor_data
            }
            monitor_info_json = json.dumps(monitor_info)

            try:
                requests.post(f'{settings.API_DATA_INGESTION_URL}/start_monitoring', data={'monitor_info': monitor_info_json})
                return JsonResponse({'status': 'success'})
            except RequestException as e:
                return JsonResponse({'status': 'error', 'message': str(e)})

    pods = get_pods(settings.CLUSTER_NAMESPACE)
    pod_choices = [(pod, pod) for pod in pods]
    model_choices = get_available_models(settings.API_CGNN_ANOMALY_DETECTION_URL)

    form = MonitoringForm()
    form.fields['containers'].choices = pod_choices
    form.fields['model'].choices = [(model, model) for model in model_choices]
    form.fields['crca_pods'].choices = pod_choices

    return render(request, 'config_app/monitoring/monitoring_setup.html', {'form': form, 'models': model_choices, 'crca_form': crca_form})


def monitoring_overview(request):
    return render(request, 'config_app/monitoring/monitoring_dashboard.html',
                  {'flask_url': settings.API_CGNN_ANOMALY_DETECTION_URL, 'monitoring_id': 234})


def load_kube_config():
    try:
        requests.post(f'{settings.API_DATA_INGESTION_URL}/load_kube_config', json={'kube_config_path': settings.KUBE_CONFIG_PATH})
        return JsonResponse({'status': 'success'})
    except RequestException as e:
        return JsonResponse({'status': 'error', 'message': str(e)})


def task_manager(request):
    return render(request, 'config_app/monitoring/monitoring_task_manager.html',
                  {'data_ingestion_url': settings.API_DATA_INGESTION_URL,
                   'cgnn_url': settings.API_CGNN_ANOMALY_DETECTION_URL,
                   'crca_url': settings.API_CRCA_ANOMALY_DETECTION_URL})
```
```user_interface/monitoring_project/config_app/views/task_results.py
import json
import requests
import pandas as pd
from django.shortcuts import render, redirect
from django.contrib import messages
from django.conf import settings
from requests.exceptions import RequestException
from io import StringIO
from django.http import JsonResponse

from .utils import get_settings


def get_results(request, task_id, task_type):
    match task_type:
        case 'crca':
            return crca_result(request, task_id)
        case 'training':
            return training_result(request)


def crca_result(request, task_id):
    try:
        response = requests.get(f'{settings.API_CRCA_ANOMALY_DETECTION_URL}/results/{task_id}')
        response_data = response.json()
        graph_images = response_data.get('graph_image', [])
        csv_data = response_data.get('ranking', '')
        csv_df = pd.read_csv(StringIO(csv_data))

        print(csv_data)

        return render(request, 'config_app/anomaly_detection/crca/crca_display_response.html', {
            'message': 'Processing complete!',
            'graph_images': graph_images,
            'ranking': csv_df.to_html(classes='table table-striped', index=False)
        })

    except RequestException as e:
        messages.error(request, f'Failed to retrieve results: {str(e)}')
        return redirect('home')


def training_result(request):
    if request.method == 'POST':
        selected_model = request.POST.get('selected_model')

        if selected_model:
            response = requests.get(f'{settings.API_LEARNING_ADAPTATION_URL}/get_available_models')
            response.raise_for_status()
            models = response.json()

            if selected_model in models:
                model_info = models[selected_model]
                model_info_json = json.dumps({
                    'settings': get_settings(),
                    'data': {selected_model: model_info}
                })

                print(model_info_json)

                try:
                    response = requests.post(
                        f'{settings.API_LEARNING_ADAPTATION_URL}/save_to_detection_module',
                        data={'model_info': model_info_json}
                    )
                    response.raise_for_status()
                    return redirect('home')
                except requests.exceptions.RequestException as e:
                    return JsonResponse({'status': 'error', 'message': str(e)})
        else:
            return JsonResponse({'status': 'error'})

    try:
        response = requests.get(f'{settings.API_LEARNING_ADAPTATION_URL}/get_available_models')
        response.raise_for_status()
        models = response.json()
        print(models)
        context = {
            'models': models
        }
        return render(request, 'config_app/training/cgnn_training_response.html', context)
    except RequestException as e:
        return JsonResponse({'status': 'error', 'message': str(e)})
```
```user_interface/monitoring_project/config_app/views/training.py
from django.shortcuts import render, redirect
from django.contrib import messages
from django.conf import settings
from requests.exceptions import RequestException
import json
import requests

from .utils import get_config, get_settings, get_metrics


def train_algorithms(request):
    return render(request, 'config_app/training/train_algorithms_home.html')


def train_cgnn(request):
    config_data = get_config(settings.API_LEARNING_ADAPTATION_URL)
    return render(request, 'config_app/training/cgnn_train_home.html', {'config': config_data})


def cgnn_train_data(request):
    if request.method == 'POST':
        selected_dataset = request.POST.get('dataset')
        selected_containers = request.POST.getlist('containers')
        selected_metrics = request.POST.getlist('metrics')
        comment = request.POST.get('comment')

        cgnn_info = {
            'dataset': selected_dataset,
            'comment': comment,
            'containers': selected_containers,
            'metrics': selected_metrics
        }
        train_info = {
            'settings': get_settings(),
            'data': cgnn_info
        }
        train_info_json = json.dumps(train_info)
        try:
            response = requests.post(settings.API_LEARNING_ADAPTATION_URL + '/cgnn_train_with_existing_dataset',
                                     data={'train_info': train_info_json})
            response_data = response.json()
            task_id = response_data.get('task_id')
            return render(request, 'config_app/waiting_page.html', {'task_id': task_id,
                                                                    'api_url': settings.API_LEARNING_ADAPTATION_URL,
                                                                    'task_type': 'training'})
        except RequestException as e:
            messages.error(request, f'Failed to train CGNN: {str(e)}')
            return redirect('cgnn_train_data')

    datasets = []

    try:
        response = requests.get(settings.API_LEARNING_ADAPTATION_URL + '/get_available_datasets')
        details = response.json()
        for key, value in details.items():
            datasets.append({
                'name': key,
                'data': value
            })
        datasets_json = json.dumps(datasets)
    except RequestException as e:
        messages.error(request, f'Failed to get available datasets: {str(e)}')

    datasets_json = json.dumps(datasets)

    return render(request, 'config_app/training/cgnn_train_data.html', {
        'datasets': datasets,
        'datasets_json': datasets_json
    })


def upload_cgnn_train_data(request):
    if request.method == 'POST':
        train_array = request.FILES['train_array']
        test_array = request.FILES['test_array']
        anomaly_label_array = request.FILES['anomaly_label_array']
        anomaly_sequence = request.POST.get('anomaly_sequence') == 'on'
        dataset = request.POST.get('dataset')
        comment = request.POST.get('comment')
        metrics = json.loads(request.POST.get('selected_metrics', '[]'))
        step_size = int(request.POST.get('step_size', 1))
        duration = int(request.POST.get('duration', 1))
        containers = json.loads(request.POST.get('containers', '[]'))

        train_files = {
            'train_array': train_array,
            'test_array': test_array,
            'anomaly_label_array': anomaly_label_array
        }
        cgnn_info = {
            'anomaly_sequence': anomaly_sequence,
            'dataset': dataset,
            'comment': comment,
            'containers': containers,
            'metrics': metrics,
            'step_size': step_size,
            'duration': duration
        }
        train_info = {
            'settings': get_settings(),
            'data': cgnn_info
        }
        train_info_json = json.dumps(train_info)
        try:
            response = requests.post(f'{settings.API_DATA_PROCESSING_URL}/preprocess_cgnn_train_data',
                                     files=train_files, data={'train_info': train_info_json})
            response_data = response.json()
            task_id = response_data.get('task_id')
            return render(request, 'config_app/waiting_page.html', {'task_id': task_id,
                                                                    'api_url': settings.API_LEARNING_ADAPTATION_URL,
                                                                    'task_type': 'training'})
        except RequestException as e:
            messages.error(request, f'Failed to train CGNN: {str(e)}')
            return redirect('train_cgnn')

    metrics = get_metrics()
    return render(request, 'config_app/training/cgnn_upload_train_data.html', {'metrics': metrics})
```
```user_interface/monitoring_project/config_app/views/update_config.py
from .utils import update_config, update_config_internal
from django.conf import settings


def config(request):
    return update_config_internal(request, 'home')


def config_cgnn(request):
    return update_config(request, settings.API_CGNN_ANOMALY_DETECTION_URL, 'perform_anomaly_detection_cgnn')


def config_crca(request):
    return update_config(request, settings.API_CRCA_ANOMALY_DETECTION_URL, 'perform_anomaly_detection_crca')


def config_cgnn_train(request):
    return update_config(request, settings.API_LEARNING_ADAPTATION_URL, 'train_cgnn')
```
```user_interface/monitoring_project/config_app/views/utils.py
import requests
import json
from requests.exceptions import RequestException
from django.shortcuts import render, redirect
from django.contrib import messages
from django.conf import settings

from ..forms import create_dynamic_form


def get_available_models(api_url):
    try:
        response = requests.get(f'{api_url}/get_available_models')
        return response.json()
    except RequestException:
        return {}


def get_config(API_URL):
    try:
        config_url = f'{API_URL}/get_config'
        response = requests.get(config_url)
        return response.json()
    except RequestException:
        return {}


def update_config(request, API_URL, redirect_url):
    config_data = get_config(API_URL)
    ConfigForm = create_dynamic_form(config_data)
    if request.method == 'POST':
        form = ConfigForm(request.POST)
        if form.is_valid():
            try:
                requests.post(f'{API_URL}/update_config', json=form.cleaned_data)
                messages.success(request, 'Config updated successfully!')
                return redirect(redirect_url)
            except requests.RequestException as e:
                messages.error(request, f'Failed to update: {str(e)}')
    else:
        form = ConfigForm()
    return render(request, 'config_app/update_config.html', {'form': form, 'redirect_url': redirect_url})


def update_config_internal(request, redirect_url):
    config_path = 'monitoring_project/config.json'
    with open(config_path) as config_file:
        config_data = json.load(config_file)

    ConfigForm = create_dynamic_form(config_data)

    if request.method == 'POST':
        form = ConfigForm(request.POST)
        if form.is_valid():
            updated_config = {key: form.cleaned_data[key] for key in config_data.keys()}
            with open(config_path, 'w') as config_file:
                json.dump(updated_config, config_file, indent=4)
            return redirect(redirect_url)
    else:
        form = ConfigForm()

    return render(request, 'config_app/update_config.html', {'form': form, 'redirect_url': redirect_url})


def get_metrics():
    try:
        response = requests.get(f'{settings.API_DATA_INGESTION_URL}/get_metrics')
        return response.json()
    except RequestException:
        return {}


def get_pods(namespace):
    try:
        response = requests.post(f'{settings.API_DATA_INGESTION_URL}/get_pod_names', json={'namespace': namespace})
        return response.json()
    except RequestException:
        return []


def get_settings():
    exposed_settings = {
        'API_DATA_INGESTION_URL': settings.API_DATA_INGESTION_URL,
        'API_DATA_PROCESSING_URL': settings.API_DATA_PROCESSING_URL,
        'API_CRCA_ANOMALY_DETECTION_URL': settings.API_CRCA_ANOMALY_DETECTION_URL,
        'API_CGNN_ANOMALY_DETECTION_URL': settings.API_CGNN_ANOMALY_DETECTION_URL,
        'API_LEARNING_ADAPTATION_URL': settings.API_LEARNING_ADAPTATION_URL,
        'PROMETHEUS_URL': settings.PROMETHEUS_URL,
        'CLUSTER_NAMESPACE': settings.CLUSTER_NAMESPACE,
        'KUBE_CONFIG_PATH': settings.KUBE_CONFIG_PATH,
    }
    return exposed_settings
```
```user_interface/monitoring_project/config_app/templates/config_app/monitoring/monitoring_dashboard.html
{% extends "base.html" %}

{% block title %}Monitoring Dashboard{% endblock %}

{% block sidebar %}
<div class="sidebar bg-light text-dark p-4 shadow">
    <h4 class="text-dark mb-4">Tasks</h4>
    <ul id="taskIdList" class="list-unstyled">
    </ul>
</div>
{% endblock %}

{% block content_class %}with-sidebar{% endblock %}

{% block content %}
<div class="container-fluid">
    <div class="row">
        <div class="col-md-12">
            <h1 class="text-center my-4">Monitoring Dashboard</h1>
            <div id="taskDetails" class="task-details mb-4 p-4 bg-light rounded shadow-sm">
            </div>
            <div class="chart-container bg-white p-4 rounded shadow-sm">
                <canvas id="monitoringChart" width="400" height="200"></canvas>
            </div>
            <div id="crcaTaskDetails" class="crca-task-details mt-4 p-4 bg-white rounded shadow-sm">
            </div>
        </div>
    </div>
</div>

<script>
    document.addEventListener('DOMContentLoaded', function () {
        const flaskUrl = "{{ flask_url|safe }}";
        let chartInstance = null;
        let allResults = {};

        async function fetchResults() {
            const response = await fetch(`${flaskUrl}/get_all_results`, {
                method: 'GET',
                headers: {
                    'Content-Type': 'application/json'
                }
            });
            if (!response.ok) {
                throw new Error(`HTTP error! Status: ${response.status}`);
            }
            return response.json();
        }

        function formatStartTime(startTime) {
            const date = new Date(startTime * 1000);
            return date.toLocaleString();
        }

        function populateSidebar(results) {
            const taskIdList = document.getElementById('taskIdList');
            taskIdList.innerHTML = '';

            const taskIdStartTimes = Object.keys(results).map(taskId => {
                const firstResult = results[taskId].results[0];
                const startTime = firstResult ? firstResult.start_time : null;
                return { taskId, startTime };
            });

            taskIdStartTimes.sort((a, b) => b.startTime - a.startTime);

            taskIdStartTimes.forEach(({ taskId, startTime }) => {
                const listItem = document.createElement('li');
                listItem.classList.add('mb-2');
                const link = document.createElement('a');
                link.href = "#";
                link.textContent = "Session: " + formatStartTime(startTime);
                link.classList.add('text-decoration-none', 'text-dark', 'd-block', 'py-1', 'px-1', 'rounded', 'sidebar-link');
                link.addEventListener('click', () => {
                    displayTaskDetails(results[taskId]);
                    plotData(results[taskId].results);
                });
                listItem.appendChild(link);
                taskIdList.appendChild(listItem);
            });
        }

        function displayTaskDetails(taskData) {
            const taskDetails = document.getElementById('taskDetails');
            const startTimeFormatted = formatStartTime(taskData.start_time);
            const containersFormatted = taskData.containers.join(', ');
            const metricsFormatted = taskData.metrics.join(', ');

            taskDetails.innerHTML = `
                <h3 class="my-3">Task Details</h3>
                <p><strong>Model:</strong> ${taskData.model}</p>
                <p><strong>Start Time:</strong> ${startTimeFormatted}</p>
                <p><strong>Containers:</strong> ${containersFormatted}</p>
                <p><strong>Metrics:</strong> ${metricsFormatted}</p>
            `;

            const crcaTaskIds = Object.values(taskData.results)
                .filter(result => result.percentage > taskData.crca_threshold)
                .map(result => ({ crca_task_id: result.crca_task_id, start_time: result.start_time }));

            if (crcaTaskIds.length > 0) {
                populateCrcaDropdown(crcaTaskIds);
            }
        }

        function populateCrcaDropdown(crcaTaskIds) {
            const crcaTaskDetails = document.getElementById('crcaTaskDetails');
            crcaTaskDetails.innerHTML = `
                <h2>Select CRCA Task ID</h2>
                <select id="crcaTaskDropdown" class="form-select my-3">
                    <option disabled selected>Select CRCA Task ID</option>
                    ${crcaTaskIds.map(task => `<option value="${task.crca_task_id}">${formatStartTime(task.start_time)}</option>`).join('')}
                </select>
                <div id="crcaTaskContent"></div>
            `;

            const dropdown = document.getElementById('crcaTaskDropdown');
            dropdown.addEventListener('change', async () => {
                const selectedTaskId = dropdown.value;
                await fetchAndDisplayCrcaTaskDetails(selectedTaskId);
            });
        }

        async function fetchAndDisplayCrcaTaskDetails(taskId) {
            const response = await fetch(`http://127.0.0.1:5023/results/${taskId}`, {
                method: 'GET',
                headers: {
                    'Content-Type': 'application/json'
                }
            });
            if (!response.ok) {
                throw new Error(`HTTP error! Status: ${response.status}`);
            }
            const crcaData = await response.json();
            displayCrcaTaskDetails(crcaData);
        }

        function displayCrcaTaskDetails(crcaData) {
            const crcaTaskContent = document.getElementById('crcaTaskContent');
            crcaTaskContent.innerHTML = `
                <h2>CRCA Task Details</h2>
                <div class="text-center">
                    <h3>Graph Images</h3>
                    ${crcaData.graph_image ? `<img src="data:image/png;base64,${crcaData.graph_image}" alt="Graph Image" class="img-fluid mb-3" />` : ''}
                </div>
                <h3>CSV Data</h3>
                <div class="table-responsive">
                    ${convertCsvToTable(crcaData.ranking)}
                </div>
            `;
        }

        function convertCsvToTable(csvData) {
            const lines = csvData.split('\n');
            const table = document.createElement('table');
            table.classList.add('table', 'table-striped', 'table-bordered');

            lines.forEach((line, index) => {
                const row = table.insertRow();
                const cells = line.split(',');
                cells.forEach(cell => {
                    const cellElement = index === 0 ? row.insertCell('th') : row.insertCell();
                    cellElement.textContent = cell;
                });
            });

            return table.outerHTML;
        }

        function plotData(data) {
            const labels = Object.values(data).map(item => {
                const date = new Date(item.end_time * 1000);
                return date.toLocaleString();
            });
            const values = Object.values(data).map(item => item.percentage);

            const ctx = document.getElementById('monitoringChart').getContext('2d');

            if (chartInstance) {
                chartInstance.destroy();
            }

            chartInstance = new Chart(ctx, {
                type: 'line',
                data: {
                    labels: labels,
                    datasets: [{
                        label: 'Anomaly Detection Results',
                        data: values,
                        borderColor: 'rgba(75, 192, 192, 1)',
                        borderWidth: 2,
                        backgroundColor: 'rgba(75, 192, 192, 0.2)'
                    }]
                },
                options: {
                    scales: {
                        y: {
                            beginAtZero: true,
                            title: {
                                display: true,
                                text: 'Percentage'
                            }
                        },
                        x: {
                            title: {
                                display: true,
                                text: 'End Time'
                            }
                        }
                    },
                    plugins: {
                        legend: {
                            display: true,
                            position: 'top',
                            labels: {
                                color: '#333'
                            }
                        }
                    }
                }
            });
        }

        async function updateDashboard() {
            try {
                allResults = await fetchResults();
                populateSidebar(allResults);
                const firstTaskId = Object.keys(allResults)[0];
                displayTaskDetails(allResults[firstTaskId]);
                plotData(allResults[firstTaskId].results);
            } catch (error) {
                console.error('Error fetching results:', error);
            }
        }

        updateDashboard();
    });
</script>

<style>
.sidebar-link {
    transition: background-color 0.3s ease, color 0.3s ease;
}
.sidebar-link:hover {
    background-color: #f0f0f0 !important;
    color: #000000 !important;
    text-decoration: none !important;
    font-weight: bold !important;
}
.text-center img {
    display: block;
    margin-left: auto;
    margin-right: auto;
}
</style>
{% endblock %}
```
```user_interface/monitoring_project/config_app/templates/config_app/monitoring/monitoring_task_manager.html
{% extends "base.html" %}

{% block title %}Task Manager{% endblock %}

{% block content %}
<div class="container mt-5">
    <h1 class="text-center mb-4">Task Manager</h1>
    <div class="row">
        <div class="col-md-12">
            <h3 class="text-center my-4">Active Tasks</h3>
            <ul id="activeTasksList" class="list-group mb-4 p-4 bg-light rounded shadow-sm"></ul>
            <div id="taskDetails"></div>
            <h3 class="text-center my-4">Results</h3>
            <ul id="resultsList" class="list-group mb-4 p-4 bg-light rounded shadow-sm"></ul>
        </div>
    </div>
</div>
{% endblock %}

{% block extra_scripts %}
<script>
    const dataIngestionUrl = "{{ data_ingestion_url|safe }}";
    const cgnnUrl = "{{ cgnn_url|safe }}";
    const crcaUrl = "{{ crca_url|safe }}";
    let activeTasks = {};

    document.addEventListener('DOMContentLoaded', function() {
        fetchActiveTasks();
        fetchResults();
    });

    async function fetchActiveTasks() {
        try {
            console.log(`Fetching active tasks from ${dataIngestionUrl}/get_active_tasks`);
            const response = await fetch(`${dataIngestionUrl}/get_active_tasks`, {
                method: 'GET',
                headers: {
                    'Content-Type': 'application/json'
                }
            });
            if (!response.ok) {
                throw new Error(`HTTP error! Status: ${response.status}`);
            }
            const data = await response.json();
            console.log('Active tasks:', data);
            activeTasks = data;
            populateActiveTasksList();
        } catch (error) {
            console.error('Failed to fetch active tasks:', error);
        }
    }

    function populateActiveTasksList() {
        const activeTasksList = document.getElementById('activeTasksList');
        activeTasksList.innerHTML = '';

        if (Object.keys(activeTasks).length === 0) {
            const noTasksItem = document.createElement('li');
            noTasksItem.classList.add('list-group-item', 'text-center');
            noTasksItem.textContent = 'No active tasks found.';
            activeTasksList.appendChild(noTasksItem);
        } else {
            Object.keys(activeTasks).forEach(worker => {
                activeTasks[worker].forEach(task => {
                    const listItem = document.createElement('li');
                    listItem.classList.add('list-group-item', 'd-flex', 'justify-content-between', 'align-items-center', 'flex-wrap');
                    listItem.innerHTML = `<span class="task-id">Task ID: ${task.id}</span>`;
                    const stopButton = document.createElement('button');
                    stopButton.classList.add('btn', 'btn-danger', 'btn-sm', 'ml-2');
                    stopButton.textContent = 'Stop';
                    stopButton.onclick = () => stopTask(task.id);
                    listItem.appendChild(stopButton);
                    activeTasksList.appendChild(listItem);
                });
            });
        }
    }

    async function stopTask(taskId) {
        const response = await fetch(`${dataIngestionUrl}/stop_monitoring/${taskId}`, {
            method: 'DELETE',
            headers: {
                'Content-Type': 'application/json'
            }
        });
        if (!response.ok) {
            throw new Error(`HTTP error! Status: ${response.status}`);
        }
        const result = await response.json();
        alert(result.status);
        fetchActiveTasks();
    }

    async function fetchResults() {
        try {
            console.log(`Fetching results from ${cgnnUrl}/get_all_results`);
            const response = await fetch(`${cgnnUrl}/get_all_results`, {
                method: 'GET',
                headers: {
                    'Content-Type': 'application/json'
                }
            });
            if (!response.ok) {
                throw new Error(`HTTP error! Status: ${response.status}`);
            }
            const data = await response.json();
            console.log('Results:', data);
            populateResultsList(data);
        } catch (error) {
            console.error('Failed to fetch results:', error);
        }
    }

    function formatStartTime(startTime) {
        const date = new Date(startTime * 1000);
        return date.toLocaleString();
    }

    function populateResultsList(results) {
        const resultsList = document.getElementById('resultsList');
        resultsList.innerHTML = '';

        if (Object.keys(results).length === 0) {
            const noResultsItem = document.createElement('li');
            noResultsItem.classList.add('list-group-item', 'text-center');
            noResultsItem.textContent = 'No results found.';
            resultsList.appendChild(noResultsItem);
        } else {
            Object.keys(results).forEach(taskId => {
                const result = results[taskId];
                const startTimeFormatted = formatStartTime(result.start_time);
                const containersFormatted = result.containers.join(', ');
                const metricsFormatted = result.metrics.join(', ');

                const listItem = document.createElement('li');
                listItem.classList.add('list-group-item', 'd-flex', 'flex-column');

                const detailsDiv = document.createElement('div');
                detailsDiv.innerHTML = `
                    <strong>Task ID:</strong> ${taskId}<br>
                    <strong>Start Time:</strong> ${startTimeFormatted}<br>
                    <strong>Dataset:</strong> ${result.model}<br>
                    <span class="expandable" onclick="toggleDetails(this)" style="cursor: pointer; color: blue; text-decoration: underline;">Show Containers and Metrics</span>
                    <div class="details" style="display: none;">
                        <strong>Containers:</strong> ${containersFormatted}<br>
                        <strong>Metrics:</strong> ${metricsFormatted}
                    </div>
                `;

                const buttonDiv = document.createElement('div');
                buttonDiv.classList.add('mt-2', 'd-flex', 'justify-content-end');

                const deleteButton = document.createElement('button');
                deleteButton.classList.add('btn', 'btn-danger', 'btn-sm');
                deleteButton.textContent = 'Delete';
                deleteButton.onclick = () => deleteResult(taskId);

                buttonDiv.appendChild(deleteButton);
                listItem.appendChild(detailsDiv);
                listItem.appendChild(buttonDiv);
                resultsList.appendChild(listItem);
            });
        }
    }

    function toggleDetails(element) {
        const detailsDiv = element.nextElementSibling;
        if (detailsDiv.style.display === 'none') {
            detailsDiv.style.display = 'block';
            element.textContent = 'Hide Containers and Metrics';
        } else {
            detailsDiv.style.display = 'none';
            element.textContent = 'Show Containers and Metrics';
        }
    }

    async function deleteResult(taskId) {
        const response = await fetch(`${cgnnUrl}/delete_results`, {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json'
            },
            body: JSON.stringify({ taskId: taskId, crcaLink: crcaUrl }) // Send data in the request body
        });
        if (!response.ok) {
            throw new Error(`HTTP error! Status: ${response.status}`);
        }
        const result = await response.json();
        alert(result.success);
        fetchResults();
    }

</script>
{% endblock %}
```

```k8s/cgnn_anomaly_detection-deployment.yml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: cgnn-anomaly-detection-deployment
  namespace: cloudsentinel
spec:
  replicas: 1
  selector:
    matchLabels:
      app: cgnn-anomaly-detection
  template:
    metadata:
      labels:
        app: cgnn-anomaly-detection
    spec:
      containers:
      - name: cgnn-anomaly-detection
        image: jojojochem/anomaly_detection_cgnn:latest
        ports:
        - containerPort: 5013
        resources:
          requests:
            memory: "128Mi"
            cpu: "250m"
          limits:
            memory: "256Mi"
            cpu: "500m"
---
apiVersion: v1
kind: Service
metadata:
  name: cgnn-anomaly-detection-service
  namespace: cloudsentinel
spec:
  selector:
    app: cgnn-anomaly-detection
  ports:
    - protocol: TCP
      port: 80
      targetPort: 5013
```
```k8s/crca_anomaly_detection-celery-deployment.yml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: crca-anomaly-detection-celery-deployment
  namespace: cloudsentinel
spec:
  replicas: 1
  selector:
    matchLabels:
      app: crca-anomaly-detection-celery
  template:
    metadata:
      labels:
        app: crca-anomaly-detection-celery
    spec:
      containers:
      - name: crca-anomaly-detection-celery
        image: jojojochem/anomaly_detection_crca:latest
        command: ["celery", "-A", "tasks.celery", "worker", "--loglevel=info", "-P", "gevent"]
        env:
        - name: CELERY_BROKER_URL
          value: "redis://redis:6379/1"
        - name: CELERY_RESULT_BACKEND
          value: "redis://redis:6379/1"
        resources:
          requests:
            memory: "128Mi"
            cpu: "250m"
          limits:
            memory: "256Mi"
            cpu: "500m"
```
```k8s/crca_anomaly_detection-deployment.yml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: crca-anomaly-detection-deployment
  namespace: cloudsentinel
spec:
  replicas: 1
  selector:
    matchLabels:
      app: crca-anomaly-detection
  template:
    metadata:
      labels:
        app: crca-anomaly-detection
    spec:
      containers:
      - name: crca-anomaly-detection
        image: jojojochem/anomaly_detection_crca:latest
        ports:
        - containerPort: 5023
        env:
        - name: CELERY_BROKER_URL
          value: "redis://redis:6379/1"
        - name: CELERY_RESULT_BACKEND
          value: "redis://redis:6379/1"
        resources:
          requests:
            memory: "128Mi"
            cpu: "250m"
          limits:
            memory: "256Mi"
            cpu: "500m"
---
apiVersion: v1
kind: Service
metadata:
  name: crca-anomaly-detection-service
  namespace: cloudsentinel
spec:
  selector:
    app: crca-anomaly-detection
  ports:
    - protocol: TCP
      port: 80
      targetPort: 5023
```
```k8s/data_ingestion_celery-deployment.yml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: celery-worker-deployment
  namespace: cloudsentinel
spec:
  replicas: 1
  selector:
    matchLabels:
      app: celery-worker
  template:
    metadata:
      labels:
        app: celery-worker
    spec:
      containers:
      - name: celery-worker
        image: jojojochem/data_ingestion:latest
        command: ["celery", "-A", "app.celery", "worker", "--loglevel=info"]
        env:
        - name: CELERY_BROKER_URL
          value: "redis://redis:6379/0"
        - name: CELERY_RESULT_BACKEND
          value: "redis://redis:6379/0"
        resources:
          requests:
            memory: "128Mi"
            cpu: "250m"
          limits:
            memory: "256Mi"
            cpu: "500m"
```
```k8s/data_ingestion-deployment.yml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: data-ingestion-deployment
  namespace: cloudsentinel
spec:
  replicas: 1
  selector:
    matchLabels:
      app: data-ingestion
  template:
    metadata:
      labels:
        app: data-ingestion
    spec:
      containers:
      - name: data-ingestion
        image: jojojochem/data_ingestion:latest
        ports:
        - containerPort: 5001
        env:
        - name: CELERY_BROKER_URL
          value: "redis://redis:6379/0"
        - name: CELERY_RESULT_BACKEND
          value: "redis://redis:6379/0"
        resources:
          requests:
            memory: "128Mi"
            cpu: "250m"
          limits:
            memory: "256Mi"
            cpu: "500m"
---
apiVersion: v1
kind: Service
metadata:
  name: data-ingestion-service
  namespace: cloudsentinel
spec:
  selector:
    app: data-ingestion
  ports:
    - protocol: TCP
      port: 80
      targetPort: 5001
```
```k8s/data_processing-deployment.yml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: data-processing-deployment
  namespace: cloudsentinel
spec:
  replicas: 1
  selector:
    matchLabels:
      app: data-processing
  template:
    metadata:
      labels:
        app: data-processing
    spec:
      containers:
      - name: data-processing
        image: jojojochem/data_processing:latest
        ports:
        - containerPort: 5002
        resources:
          requests:
            memory: "128Mi"
            cpu: "250m"
          limits:
            memory: "256Mi"
            cpu: "500m"
---
apiVersion: v1
kind: Service
metadata:
  name: data-processing-service
  namespace: cloudsentinel
spec:
  selector:
    app: data-processing
  ports:
    - protocol: TCP
      port: 80
      targetPort: 5002
```
```k8s/learning_adaptation-celery-deployment.yml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: learning-adaptation-celery-deployment
  namespace: cloudsentinel
spec:
  replicas: 1
  selector:
    matchLabels:
      app: learning-adaptation-celery
  template:
    metadata:
      labels:
        app: learning-adaptation-celery
    spec:
      containers:
      - name: learning-adaptation-celery
        image: jojojochem/learning_adaptation:latest
        command: ["celery", "-A", "tasks", "worker", "--loglevel=info"]
        env:
        - name: CELERY_BROKER_URL
          value: "redis://redis:6379/2"
        - name: CELERY_RESULT_BACKEND
          value: "redis://redis:6379/2"
        resources:
          requests:
            memory: "128Mi"
            cpu: "250m"
          limits:
            memory: "256Mi"
            cpu: "500m"
```
```k8s/learning_adaptation-deployment.yml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: learning-adaptation-deployment
  namespace: cloudsentinel
spec:
  replicas: 1
  selector:
    matchLabels:
      app: learning-adaptation
  template:
    metadata:
      labels:
        app: learning-adaptation
    spec:
      containers:
      - name: learning-adaptation
        image: jojojochem/learning_adaptation:latest
        ports:
        - containerPort: 5005
        env:
        - name: CELERY_BROKER_URL
          value: "redis://redis:6379/2"
        - name: CELERY_RESULT_BACKEND
          value: "redis://redis:6379/2"
        resources:
          requests:
            memory: "128Mi"
            cpu: "250m"
          limits:
            memory: "256Mi"
            cpu: "500m"
---
apiVersion: v1
kind: Service
metadata:
  name: learning-adaptation-service
  namespace: cloudsentinel
spec:
  selector:
    app: learning-adaptation
  ports:
    - protocol: TCP
      port: 80
      targetPort: 5005
```
```k8s/monitoring_project-deployment.yml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: monitoring-project-deployment
  namespace: cloudsentinel
spec:
  replicas: 1
  selector:
    matchLabels:
      app: monitoring-project
  template:
    metadata:
      labels:
        app: monitoring-project
    spec:
      containers:
      - name: monitoring-project
        image: jojojochem/monitoring_project:latest
        ports:
        - containerPort: 8000
        env:
        - name: API_DATA_INGESTION_URL
          value: "http://data-ingestion-service.cloudsentinel.svc.cluster.local:80"
        - name: API_DATA_PROCESSING_URL
          value: "http://data-processing-service.cloudsentinel.svc.cluster.local:80"
        - name: API_CRCA_ANOMALY_DETECTION_URL
          value: "http://crca-anomaly-detection-service.cloudsentinel.svc.cluster.local:80"
        - name: API_CGNN_ANOMALY_DETECTION_URL
          value: "http://cgnn-anomaly-detection-service.cloudsentinel.svc.cluster.local:80"
        - name: API_LEARNING_ADAPTATION_URL
          value: "http://learning-adaptation-service.cloudsentinel.svc.cluster.local:80"
        - name: PROMETHEUS_URL
          value: "http://prometheus-server.monitoring.svc.cluster.local:80"
        - name: CLUSTER_NAMESPACE
          value: kube-system
        - name: KUBE_CONFIG_PATH
          value:
        resources:
          requests:
            memory: "256Mi"
            cpu: "500m"
          limits:
            memory: "512Mi"
            cpu: "1"
---
apiVersion: v1
kind: Service
metadata:
  name: monitoring-project-service
  namespace: cloudsentinel
spec:
  selector:
    app: monitoring-project
  ports:
    - protocol: TCP
      port: 80
      targetPort: 8000
  type: LoadBalancer
```
```k8s/namespace-deployment.yml
apiVersion: v1
kind: Namespace
metadata:
  name: cloudsentinel
```
```k8s/redis-deployment.yml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: redis-deployment
  namespace: cloudsentinel
spec:
  replicas: 1
  selector:
    matchLabels:
      app: redis
  template:
    metadata:
      labels:
        app: redis
    spec:
      containers:
      - name: redis
        image: redis:latest
        ports:
        - containerPort: 6379
        resources:
          requests:
            memory: "128Mi"
            cpu: "100m"
          limits:
            memory: "256Mi"
            cpu: "200m"
---
apiVersion: v1
kind: Service
metadata:
  name: redis
  namespace: cloudsentinel
spec:
  selector:
    app: redis
  ports:
    - protocol: TCP
      port: 6379
      targetPort: 6379
```
```.github/workflows/deploy.yml
name: CI/CD Pipeline

on:
  push:
    branches:
      - main

jobs:
  build-and-deploy:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout code
      uses: actions/checkout@v2

    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v1

    - name: Log in to Docker Hub
      uses: docker/login-action@v1
      with:
        username: ${{ secrets.DOCKER_USERNAME }}
        password: ${{ secrets.DOCKER_PASSWORD }}

    - name: Build and push Docker images
      run: |
        docker build -t jojojochem/data_ingestion:latest -f data_ingestion/Dockerfile data_ingestion/
        docker build -t jojojochem/data_processing:latest -f data_processing/Dockerfile data_processing/
        docker build -t jojojochem/anomaly_detection_cgnn:latest -f anomaly_detection/cgnn/Dockerfile anomaly_detection/cgnn/
        docker build -t jojojochem/anomaly_detection_crca:latest -f anomaly_detection/crca/Dockerfile anomaly_detection/crca/
        docker build -t jojojochem/learning_adaptation:latest -f learning_adaptation/Dockerfile learning_adaptation/
        docker build -t jojojochem/monitoring_project:latest -f user_interface/monitoring_project/Dockerfile user_interface/monitoring_project/
        docker push jojojochem/data_ingestion:latest
        docker push jojojochem/data_processing:latest
        docker push jojojochem/anomaly_detection_cgnn:latest
        docker push jojojochem/anomaly_detection_crca:latest
        docker push jojojochem/learning_adaptation:latest
        docker push jojojochem/monitoring_project:latest
        docker run -d -p 5001:5001 jojojochem/data_ingestion:latest
        docker run -d -p 5002:5002 jojojochem/data_processing:latest
        docker run -d -p 5023:5023 jojojochem/anomaly_detection_cgnn:latest
        docker run -d -p 5013:5013 jojojochem/anomaly_detection_crca:latest
        docker run -d -p 5005:5005 jojojochem/learning_adaptation:latest
        docker run -d -p 8000:8000 jojojochem/monitoring_project:latest

    - name: Create .kube directory
      run: |
        mkdir -p $HOME/.kube
    - name: Set up kubeconfig
      run: |
        echo "${{ secrets.KUBECONFIG }}" > $HOME/.kube/config

    - name: Set up Kubernetes
      uses: azure/k8s-set-context@v1
      with:
        method: kubeconfig
        kubeconfig: $HOME/.kube/config

    - name: Deploy to Kubernetes
      run: |
        kubectl apply -f k8s/namespace-deployment.yml
        kubectl apply -f k8s/redis-deployment.yml
        kubectl apply -f k8s/data_ingestion_celery-deployment.yml
        kubectl apply -f k8s/data_ingestion-deployment.yml
        kubectl apply -f k8s/data_processing-deployment.yml
        kubectl apply -f k8s/cgnn_anomaly_detection-deployment.yml
        kubectl apply -f k8s/crca_anomaly_detection-deployment.yml
        kubectl apply -f k8s/learning_adaptation-deployment.yml
        kubectl apply -f k8s/learning_adaptation-celery-deployment.yml
        kubectl apply -f k8s/crca_anomaly_detection-celery-deployment.yml
        kubectl apply -f k8s/monitoring_project-deployment.yml
```